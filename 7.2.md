# 7.2学习日志

## 必要时进行保护性拷贝

&emsp;&emsp;让 Java 使用起来如此舒适的一个因素在于，它是一门*安全的语言（safe language）*。这意味着，在没有 native 方法的情况下，它对于缓冲区溢出、数组越界、非法指针以及其他的内存破坏错误都自动免疫，而这些错误却困扰着诸如 C 和 C++这样的不安全的语言。在一门安全语言中，无论系统的其他部分发生什么事情，这些类的约束都是有效的。对于那些“把所有的内存当作一个巨大的数组来看待”的语言来说，这是不可能的。

&emsp;&emsp;即使在安全的语言中，如果不采取一点措施，还是无法与其他的类隔离开来。**假设类的客户端会尽其所能来破坏这个类的约束条件，因此你必须保护性地设计程序**。随着人们为了破坏系统的安全性而付出了更多的努力，这种做法越来越正确，但更常见的是，你的类不得不处理那些善意的程序猿意外导致的错误。不管怎么说，编写一些面对客户出现不良行为时仍能保持健壮性的类，这是非常值得投入时间去做的事情。

&emsp;&emsp;没有对象的帮助时，虽然另一个类不可能修改对象的内部状态，但是对象很容易在无意识的情况下提供这种帮助。例如，考虑下面的类，它声称可以代表一段不可变的时间周期：

```java
// Broken "immutable" time period class
public final class Period {
    private final Date start;
    private final Date end;
    /**
    * @param start the beginning of the period
    * @param end the end of the period; must not precede start
    * @throws IllegalArgumentException if start is after end
    * @throws NullPointerException if start or end is null
    */
    public Period(Date start, Date end) {
        if (start.compareTo(end) > 0)
            throw new IllegalArgumentException(start + " after " + end);
        this.start = start;
        this.end = end;
    }
    public Date start() {
        return start;
    }
    public Date end() {
        return end;
    }
    ... // Remainder omitted
}
```

&emsp;&emsp;乍一看，这个类似乎是不可变的，并且强加了约束条件：周期的起始时间（start）不能在结束时间（end）之后。然而，因为 Date 类本身是可变的，因此很容易违反这个约束条件：

```java
// Attack the internals of a Period instance
Date start = new Date();
Date end = new Date();
Period p = new Period(start, end);
end.setYear(78); // Modifies internals of p!
```

&emsp;&emsp;从 Java 8 开始，解决此问题的显而易见的方法是使用 Instant（或 LocalDateTime 或 ZonedDateTime）代替 Date，因为 Instant（和其他 java.time 类）是不可变的（第 17 项）。**Date 已过时，不应再在新的代码中使用**。也就是说，问题仍然存在：有时你必须在 API 和内部表示中使用可变值类型，此项中讨论的技术就适合在这种情况下使用。

&emsp;&emsp;为了保护 Period 实例的内部信息避免受到这种攻击，**对于构造器的每个可变参数进行保护性拷贝（defensive copy）是必要的**，并且使用备份对象作为 Period 实例的组件，而不使用原始的对象：

```java
// Repaired constructor - makes defensive copies of parameters
public Period(Date start, Date end) {
    this.start = new Date(start.getTime());
    this.end = new Date(end.getTime());
    if (this.start.compareTo(this.end) > 0)
        throw new IllegalArgumentException(this.start + " after " + this.end);
}
```

&emsp;&emsp;使用新的构造函数，先前的攻击对 Period 实例没有影响。注意，**保护性拷贝是在检查参数的有效性（第 49 项）之前进行的，并且有效性检查是针对拷贝之后的对象，而不是针对原始的对象**。虽然这样做看起来有点不自然，却是必要的。这样做可以避免在*危险阶段（window of vulnerability）*期间从另一个线程改变类的参数，这里的危险阶段是指从检查参数开始直到拷贝参数之间的时间段。在计算机安全区中，这被称作*time-of-check/time-of-use*或者 TOCTOU 攻击\[Viega01\]。

&emsp;&emsp;同时也请注意，我们没有用 Date 的 clone 方法来进行保护性拷贝。因为 Date 是非 final 的，不能保证 clone 方法一定返回类为 java.util.Date 的对象：它有可能返回专门出于恶意的目的而设计的不可信子类的实例。例如，这样的子类可以在每个实例被创建的时候，把指向该实例的引用记录到一个私有的静态列表中，并且允许攻击者访问这个列表。这将使得攻击者可以自由地控制所有的实例。为了阻止这种攻击，**对于参数类型可以被不可信任方子类化的参数，请不要使用 clone 方法进行保护性拷贝**。

&emsp;&emsp;虽然替换构造函数就可以成功避免上述的攻击，但是改变 Period 实例仍然是有可能的，因为它的访问方法提供了对其可变内部成员的访问能力：

```java
// Second attack on the internals of a Period instance
Date start = new Date();
Date end = new Date();
Period p = new Period(start, end);
p.end().setYear(78); // Modifies internals of p!
```

&emsp;&emsp;为了防御这第二种攻击，只要修改这两个访问方法，**使它返回可变内部域的保护性拷贝即可**：

```java
// Repaired accessors - make defensive copies of internal fields
public Date start() {
    return new Date(start.getTime());
}
public Date end() {
    return new Date(end.getTime());
}
```

&emsp;&emsp;使用了新的构造函数和访问方法之后，Period 真正是不可变的了。不管程序猿是多么恶意，或者多么不合格，都绝对不会违反周期的起始时间不能落后于结束时间这个约束条件（不采用诸如 native 方法和反射之类的语言手段）。确实如此，因为除了 Period 类自身之外，其他任何类都无法访问 Period 实例中的任何一个可变域，这些域被真正封装在对象的内部。

&emsp;&emsp;访问方法和构造器不同，它们在进行保护性拷贝的时候允许使用 clone 方法。之所以如此，是因为我们知道，Period 内部的 Date 对象的类是 java.util.Date，而不可能是其他某个潜在的不可信子类。也就是说，基于第 13 项中所阐述的原因，一般情况下，最好使用构造函数或者静态工厂。

&emsp;&emsp;参数的保护性拷贝并不仅仅针对不可变类。每当编写方法或者构造器的，使用内部数据结构来存储客户端提供的对对象的引用时，请考虑一下，客户端提供的对象是否有可能是可变的。如果是，考虑一下你的类在输入数据结构后是否可以容忍对象的更改。如果答案是否，就必须对该对象进行保护性拷贝，并且让拷贝之后的对象而不是原始对象存入到数据结构中。例如，如果你正在考虑使用由客户端提供的对象引用作为内部 Set 实例的元素，或者作为内部 Map 实例的键（key），就应该意识到，如果这个对象在插入之后再被修改，Set 或者 Map 的约束条件就会遭到破坏。

&emsp;&emsp;在内部组件被返回客户端之前，对它们进行保护性拷贝也是同样的道理。不管你的类是否为不可变的，在把一个指向内部可变组件的引用返回给客户端之前，也应该加倍认真地考虑。解决方案是，应该返回保护性拷贝。记住长度非零的数组总是可变的。因此，在把内部数组返回给客户端之前，应该总是要进行保护性拷贝。另一种解决方案是，给客户端返回该数组的不可变视图（immutable view）。这两种方法在第 15 项已经演示过了。

&emsp;&emsp;可以肯定地说，上述的真正启示在于，只要有可能，都应该使用不可变的对象作为对象内部的组件，这样就不必再为保护性拷贝（第 17 项）操心。在前面的 Period 例子中，使用 Instant (或 LocalDateTime 或 ZonedDateTime), 除非你使用的是 Java 8 之前的版本。如果你使用的是更早的版本，一个选择是存储 Date.getTime()返回的基本类型 long 代替 Date 引用。

&emsp;&emsp;保护性拷贝可能会带来相应的性能损失，这种说法并不总是正确的。如果类信任它的调用者不会修改内部的组件，可能因为类及其客户端都在同一个包里，那么不进行保护性拷贝也是可以的。在这种情况下，类的文档中就必须清楚地说明，调用者绝不能修改受到影响的参数或返回值。

&emsp;&emsp;即使跨越包的作用范围，也并不总是适合在将可变参数整合到对象中之前，对它进行保护性拷贝。有一些方法和构造器的调用，要求参数所引用的对象必须有个显示的*交接（handoff）*过程。当客户端调用这样的方法时，它承诺以后不再直接修改该对象。如果方法或者构造器期望接管一个由客户端提供的可变对象，它就必须在文档中明确地指明这一点。

&emsp;&emsp;如果类所包含的方法或者构造函数的调用需要移交对象的控制权，这个类就无法让自身抵御恶意的客户端。只有当类和它的客户端之间相互信任，或者破坏类的约束条件不会伤害到除了客户端之外的其他对象时，这种类才是可以接受的。后一种情形的例子是包装类模式（wrapper class pattern）（第 18 项）。根据包装类的本质特征，客户端只需要在对象被包装之后直接访问它，就可以破坏包装类的约束条件，但是，这么做往往只会伤害到客户端自己。

&emsp;&emsp;简而言之，如果类具有从客户端得到或者返回给客户端的可变组件，类就必须保护性地拷贝这些组件。如果拷贝的成本受到限制，并且类信任它的客户端不会不恰当地修改组件，就可以在文档中指明客户端的职责是不得修改受到影响的组件，以此来代替保护性拷贝。


## 慎用重载

&emsp;&emsp;下面这个程序的目的是明确的，它试图根据一个集合（collection）是 Set、List，还是其他的集合类型，对它进行分类：

```java
// Broken! - What does this program print?
public class CollectionClassifier {
    public static String classify(Set<?> s) {
        return "Set";
    }
    public static String classify(List<?> lst) {
        return "List";
    }
    public static String classify(Collection<?> c) {
        return "Unknown Collection";
    }
    public static void main(String[] args) {
        Collection<?>[] collections = {
            new HashSet<String>(),
            new ArrayList<BigInteger>(),
            new HashMap<String, String>().values()
        };
        for (Collection<?> c : collections)
            System.out.println(classify(c));
    }
}
```

&emsp;&emsp;你可能期望这个程序会打印出“Set”，紧接着是“List”，以及“Unknown Collection”。但实际上不是这样。它是打印“Unknown Collection”三次。为什么会这样呢？因为 classify 方法被*重载（overloaded）*了，而**要调用哪个重载方法是在编译时才决定的**。对于 for 循环中的三次迭代，参数的编译时类型都是用的：Collection<?>。每次迭代的运行时类型都是不同的，但这并不影响对重载方法的选择。因为该参数的编译时类型为Collection<?>，所以，唯一合适的重载方法是第三个：Collection<?>，在循环的每次迭代中，都会调用这个重载方法。

&emsp;&emsp;这个程序的行为有悖常理，因为**对于重载方法（overloaded method）的选择是静态的，而对于被覆盖的方法（overridden method）的选择则是动态的**。选择被覆盖的方法的正确版本是在运行时进行的，选择的依据是被调用方法所在对象的运行时类型。这里重新说明一下，当一个子类包含的方法声明与其祖先类中的方法声明具有相同的签名时，方法就被覆盖了。如果实例方法在子类中被覆盖了，并且这个方法是在该子类的实例上被调用，那么子类中的覆盖方法（overriding method）将会执行，而不管该子类实例的编译时类型到底是什么。为了更具体地说明，考虑下面这个程序：

```java
class Wine {
    String name() { return "wine"; }
}
class SparklingWine extends Wine {
    @Override
    String name() { return "sparkling wine"; }
}
class Champagne extends SparklingWine {
    @Override
    String name() { return "champagne"; }
}
public class Overriding {
    public static void main(String[] args) {
        List<Wine> wineList = List.of(new Wine(), new SparklingWine(), new Champagne());
        for (Wine wine : wineList)
            System.out.println(wine.name());
    }
}
```

&emsp;&emsp;name 方法是在类 Wine 中被声明的，但是在子类 SparklingWine 和 Champagne 中被覆盖。正如你所预期的那样，这个程序打印出“wine，sparking wine 和 champagne”，尽管在循环的每次迭代中，实例的编译时类型都为 Wine。当调用被覆盖的方法时，对象的编译时类型不会影响到哪个方法将被执行；“最为具体地（most specific）”那个覆盖版本总是会得到执行。这与重载的情形相比，对象的运行时类型并不影响“哪个重载版本将被执行”；选择【执行哪个版本】的工作是在编译时进行的，完全基于参数的编译时类型。

&emsp;&emsp;在 CollectionClassifier 这个示例中，该程序的目的是：根据参数的运行时类型自动将调用分发给适当的重载方法，以此来识别出参数的类型，就好像 Wine 的例子中的 name 方法所做的那样。方法重载机制完全没有提供这样的功能。假设需要有个静态方法，CollectionClassifier 程序的最佳修正方案是，用单个方法来替换这三个重载的 classify 方法，并在这个方法中做一个显式的 instanceof 判断：

```java
public static String classify(Collection<?> c) {
    return c instanceof Set ? "Set" : c instanceof List ? "List" : "Unknown Collection";
}
```

&emsp;&emsp;因为覆盖机制是规范，而重载机制是例外，所以，覆盖机制满足了人们对于方法调用行为的期望。正如 CollectionClassifier 例子所示，重载机制很容易使这些期望落空。如果编写出来的代码的行为可能使程序猿感到困惑，他就是很糟糕的实践。对于 API 来说尤其如此。如果 API 的普通用户根本不知道“对于一组给定的参数，其中的哪个重载方法将会被调用”，那么，使用这样的 API 就很可能出错。这些错误要等到运行时发生了怪异的行为之后才会显现出来，许多程序猿无法诊断出这样的错误。因此，应该**避免乱用重载机制**。

&emsp;&emsp;到底怎样才算乱用重载机制呢？这个问题仍然存在争议。**安全而保守的策略是，永远不要导出两个具有相同参数数目的重载方法**。如果方法使用可变参数（varargs），保守的策略是根本不需要重载它，除了第 53 项中描述的情形之外。如果你遵守这些限制，程序猿永远也不会陷入到“对于任何一组实际的参数，哪个重载方法是适用的”这样的疑问中。这项限制并不麻烦，因为**你始终可以给方法起不同的名称，而不使用重载机制**。

&emsp;&emsp;例如，考虑 ObjectOutputStream 这个类。对于每个基本类型，以及几种引用类型，它的 write 方法都有一种变形。这些变形方法都有不一样的名字，而不是重载 write 方法，比如 writeBoolean(boolean), writeInt(int)和 writeLong(long)。实际上，ObjectInputStream 类正是提供了这样的读方法。

&emsp;&emsp;对于构造器，你没有选择使用不同名称的机会：一个类的多个构造器总是重载的。在许多情况下，可以选择导出静态工厂，而不是构造器（第 1 项）。而且，对于构造器，还不用担心重载和覆盖的相互影响，因为构造器不可能被覆盖。或许你有可能导出多个具有相同参数数目的构造器，所以有必要了解一下如何安全地做到这一点。

&emsp;&emsp;如果对于“任何一组给定的实际参数将应用在哪个重载方法上”始终非常清楚，那么，导出多个具有相同参数数目的重载方法就不可能使程序猿感到困惑。如果对于每一对重载方法，至少有一个对应的参数在两个重载方法中具有“根本不同（radically different）”的类型，就属于这种情况。如果使用任何非空表达式都无法将两种类型相互转换，那么这两种类型就是完全不同的（Two types are radically different if it is clearly impossible to cast any non-null expression to both types）。在这种情况下，一组给定的实际参数应用于哪个重载方法上就完全由参数的运行时类型来决定，不可能受到其编译时类型的影响，所以主要的混淆根源就消除了。例如，ArrayList 有一个构造器带一个 int 参数，另一个构造器带一个 Collection 参数。难以想象在什么情况下，会不清楚要调用哪一个构造器。

&emsp;&emsp;在 Java 1.5 发行版之前，所有的基本类型与所有的引用类型都有根本上的不同，但是当自动装箱出现之后，就不再如此了，它会导致真正的麻烦。请考虑下面这个程序：

```java
public class SetList {
    public static void main(String[] args) {
        Set<Integer> set = new TreeSet<>();
        List<Integer> list = new ArrayList<>();

        for (int i = -3; i < 3; i++) {
            set.add(i);
            list.add(i);
        }
        for (int i = 0; i < 3; i++) {
            set.remove(i);
            list.remove(i);
        }
        System.out.println(set + " " + list);
    }
}
```

&emsp;&emsp;程序将-3 到 2 之间的整数添加到了排好序的集合列表中，然后在集合和列表中都进行 3 次相同的 remove 调用。如果你像大多数人一样，希望程序从集合和列表中去除非负数（0，1 和 2），并打印出\[-3,-2,-1\]、\[-3,-2,-1\]。事实上，程序从集合中去除了非负数，还从列表中去除了奇数值，打印出\[-3,-2,-1\] \[-2,0,2\]。将这种行为称之为混乱，已经是保守的说法了。

&emsp;&emsp;实际上发生的情况是：set.remove(i)选择调用的是重载方法 remove(E)，这里的 E 是集合（Integer）的元素类型，将 i 从 int 自动装箱到 Integer 中。这是你所期待的行为，因此程序不会从集合中去除正值。另一方面，list.remove(i)选择调用的是重载方法 remove(int i)，它从列表的指定位置上去除元素。如果从列表\[-3, -2, -1, 0, 1, 2\]开始，去除第零个元素，接着去除第一个、第二个，得到的是\[-2, 0, 2\]，这个秘密被揭开了。 为了解决这个问题，要将 list.remove 的参数转换成 Integer，迫使选择正确的重载方法。或者，你可以调用 Integer.valueOf(i)，并将结果传递给 list.remove。这两种方法都如我们所料，打印出\[-3,-2,-1\]、\[-3,-2,-1\]：

```java
for (int i = 0; i < 3; i++) {
    set.remove(i);
    list.remove((Integer) i); // or remove(Integer.valueOf(i))
}
```

&emsp;&emsp;前一个范例中所示的混乱行为在这里也出现了，因为 List<E>接口有两个重载的 remove 方法：remove(E)和 remove(int)。当它在 Java 1.5 发行版中被泛型化之前，List 接口有一个 remove(Object)而不是 remove(E)，相应的参数类型：Object 和 int，则根本不用。但是自从有了泛型和自动装箱之后，从根本上讲，这两种参数类型就不再不同了。换句话说，Java 语言中添加了泛型和自动装箱之后，破坏了 List 接口。幸运的是，Java 类库中几乎再没有 API 受到同样的破坏，但是这种情形清楚地说明了，自动装箱和泛型成了 Java 语言的一部分之后，谨慎重载显得更加重要了。

&emsp;&emsp;在 Java 8 中添加 lambda 和方法引用进一步增加了重载混淆的可能性。例如，考虑这两个片段：

```java
new Thread(System.out::println).start();
```

```java
ExecutorService exec = Executors.newCachedThreadPool();
exec.submit(System.out::println);
```

&emsp;&emsp;虽然 Thread 构造函数的调用和 submit 方法的调用看起来类似，但前者编译而后者不编译。参数是相同的（System.out::println），构造函数和方法都有一个带有 Runnable 的重载。这里发生了什么？答案令人惊讶：submit 方法有一个带有 Callable <T>【参数】的重载，然而 Thread 构造函数并没有。你可能认为这不应该有任何区别，因为 println 的所有重载都返回 void，因此方法引用不可能是 Callable。这很有道理，但这不是重载解析算法的工作方式。也许同样令人惊讶的是，如果 println 方法也没有重载，则 submit 方法调用将是合法的。它是重载引用方法（println）和调用方法（submit）的组合，它可以防止重载决策算法按照你的预期运行（It is the combination of the overloading of the referenced method (println) and the invoked method (submit) that prevents the overload resolution algorithm from behaving as you’d expect）。

&emsp;&emsp;从技术上讲，问题是 System.out::println 是一个不精确的方法引用\[JLS，15.13.1\]，并且“包含隐式类型的 lambda 表达式或不精确的方法引用的某些参数表达式被适用性测试忽略，因为它们的在选择目标类型之前无法确定含义\[JLS，15.12.2\]。如果你不理解这段文字的意思，不要担心; 它针对的是编译器的编写者。导致混淆关键是在同一参数位置中具有不同功能接口的重载方法或构造函数。因此，**不要重载一个方法，该方法在相同的参数位置可以接受不同的功能接口（do not overload methods to take different functional interfaces in the same argument position）**。在该项的说法中，不同的功能接口从根本上讲并不是完全不同的。如果你使用（pass）命令行开关-Xlint：overloads，出现这种有问题的重载时，Java 编译器就会警告你。

&emsp;&emsp;数组类型和 Object 之外的类截然不同。数组类型和 Serializable 与 Cloneable 之外的接口也截然不同。如果两种类都不是对方的后代，这两个独特的类就是不相关的（unrelated）\[JLS, 5.5\]。例如，String 和 Throwable 就是不相关的。任何对象都不可能是两个不相关的类的实例，因此不相关的类也是截然不同的。

&emsp;&emsp;还有其他一些“类型对”的例子也是不能相互转换的\[JLS, 5.1.12\]。但是，一旦超出了上述这些简单的情形，大多数程序猿要想搞清楚“一组实际的参数应用于哪个重载方法上”就会非常困难。确定选择哪个重载方法的规则是非常复杂的，并且每个版本都会变得更加复杂。很少有程序猿能够理解其中的所有微妙之处。

&emsp;&emsp;有时候，尤其是在更新现有类的时候，可能会被迫违反本项中的指导原则。例如，考虑 String，它自 Java 4 以来就有一个 contentEquals（StringBuffer）方法。在 Java 5 中，新增了一个 CharSequence 接口，用来为 StringBuffer，StringBuilder，String，CharBuffer 和其他类似的类型提供公共接口。在添加 CharSequence 接口的同时，String 也加（outfitted）了一个接受一个 CharSequence 类型参数的 contentEquals 方法。

&emsp;&emsp;虽然产生的重载明显违反了此项中的指导原则，但它不会造成任何损害，因为重载方法在同一对象引用上调用时会执行完全相同的操作。程序猿可能并不知道哪个重载函数会被调用，但是只要它们的行为相同，它【知道哪个重载函数会被调用】就没有任何意义。确保这种行为的标准做法是，让更具体化的重载方法把调用转发给更一般化的重载方法：

```java
// Ensuring that 2 methods have identical behavior by forwarding
public boolean contentEquals(StringBuffer sb) {
    return contentEquals((CharSequence) sb);
}
```

&emsp;&emsp;虽然 Java 平台类库很大程度上遵循了本项中的建议，但是也有诸多的类违背了。例如：String 类导出了两个重载的静态工厂方法：valueOf(char\[\])和 valueOf(Object)，当这两个方法被传递了同样的对象引用时，它们所做的事情完全不同。没有正当的理由可以解释这一点，它应该被看作是一种反常行为，有可能会造成真正的混淆。

&emsp;&emsp;简而言之，能够重载方法并不意味着就应该重载方法。一般情况下，对于多个具有相同参数数目的方法来说，应该尽量避免重载方法。在某些情况下，特别是涉及构造函数的时候，要遵循这条建议也许是不可能的。在这种情况下，至少应该避免这样的情形：同一组参数只需要经过类型转换就可以被传递给不用的重载方法。如果不能避免这种情形，例如，因为正在改造一个现有的类来实现新的接口，就应该保证：当传递同样的参数时，所有重载方法的行为必须一致。如果不能做到这一点，程序猿就很难有效地使用被重载的方法或者构造器，它们就不能理解它为什么不能正常地工作。

## 将局部变量的作用域最小化

&emsp;&emsp;本项与第 15 项（使类和成员的可访问性最小化）本质上是类似的。将局部变量的作用域最小化，可以增强代码的可读性和可维护性，并降低出错的可能性。

&emsp;&emsp;较早的程序设计语言（如 C 语言）要求局部变量必须在一个代码块的开头处进行声明，出于习惯，有些程序猿目前还是继续这样做。这是个值得打破的习惯。在此提醒 Java 允许你在任何可以出现语句的地方声明变量（与 C 一样，自 C99 起）。

&emsp;&emsp;**要使局部变量的作用域最小化，最有力的方法是在第一次使用它的地方声明** 。如果变量在使用之前进行声明，这只会造成混乱————对于试图理解程序功能的读者来说，这又多了一种只会分散他们注意力的因素。等到用到该变量的时候，读者可能已经记不起该变量的类型或者初始值了。

&emsp;&emsp;过早地声明局部变量不仅会使它的作用域开始得太早，而且结束得也过于晚了。局部变量的作用域从它被声明的点开始，一直到代码块（block）结束的地方。如果变量是在“使用它的块”之外被声明的，当程序退出该块之后，该变量仍然是可见的。如果变量在它的目标使用区域之前或者之后被意外地使用的话，后果将可能是灾难性的。

&emsp;&emsp;**几乎每个局部变量的声明都应该包含一个初始化表达式** 。如果你还没有足够的信息来对一个变量进行有意义的初始化，就应该推迟这个【变量的】声明，直到可以初始化为止。这条规则有一个例外的情况与 try-cache 语句有关。如果一个变量被一个表达式初始化，这个表达式可能会抛出一个受检异常（checked exception），该变量就必须在 try 块的内部初始化（除非封闭方法可以传播异常【意思应该是方法包含 throws exception】）。如果变量的值必须在 try 块外部被使用到，它就必须在 try 块之前被声明，但是在 try 块之前，它还不能被“有意义地初始化”。请参照【原书】第 283 页的例子。

&emsp;&emsp;循环中提供了特殊的机会来将变量的作用域最小化。无论是传统的还是 for-each 形式的 for 循环，都允许声明*循环变量（loop variable）*，它们的作用域被限定在正好需要的范围之内。（该区域由循环体和 for 关键字与正文之间括号中的代码组成。）因此，如果在循环终止之后不再需要循环变量的内容，**for 循环就优先于 while 循环** 。

&emsp;&emsp;例如，下面是一种遍历集合的首选做法（第 46 项）：

```java
// Preferred idiom for iterating over a collection or array
for (Element e : c) {
    ... // Do Something with e
}
```

&emsp;&emsp;如果你需要访问迭代器(iterator)，也许是为了调用它的 remove 方法，首选的习惯是使用传统的 for 循环用法代替 for-each 循环：

```java
// Idiom for iterating when you need the iterator
for (Iterator<Element> i = c.iterator(); i.hasNext(); ) {
    Element e = i.next();
    ... // Do something with e and i
}
```

&emsp;&emsp;为了弄清楚为什么这个 for 循环比 while 循环更好，请考虑下面的代码片段，它包含两个 while 循环，以及一个 BUG：

```java
Iterator<Element> i = c.iterator();
while (i.hasNext()) {
    doSomething(i.next());
}
...
Iterator<Element> i2 = c2.iterator();
while (i.hasNext()) { // BUG!
    doSomethingElse(i2.next());
}
```

&emsp;&emsp;第二个循环中包含一个“剪切-粘贴”错误：它初始化了一个新的变量 i2，但是使用的是旧的那个变量 i，遗憾的是，这时 i 仍然还在有效范围内。结果代码仍然可以通过编译，运行的时候也不会抛出异常，但是它所做的事情却是错误的。第二个循环并没有在 c2 上迭代，而是立即终止，造成 c2 为空的假象。因为这个程序的错误是悄然发生的，所以可能在很长时间内都不会被发现。

&emsp;&emsp;如果类似的“剪切-粘贴”错误发生在任何一种循环中（无论是传统循环的还是 for-each 循环），结果是，代码根本不能通过编译。在第二个循环开始之前，第一个循环的元素（或者迭代器）变量已经不在它的作用域范围之内了：

```java
for (Iterator<Element> i = c.iterator(); i.hasNext(); ) {
    Element e = i.next();
    ... // Do something with e and i
}
...
// Compile-time error - cannot find symbol i
for (Iterator<Element> i2 = c2.iterator(); i.hasNext(); ) {
    Element e2 = i2.next();
    ... // Do something with e2 and i2
}
```

&emsp;&emsp;而且，如果使用 for 循环，犯这种“剪切-粘贴”错误的可能性就会大大降低，因为通常没有必要在两个循环中使用不同的变量名。循环是完全独立的，所以重用元素（或者迭代器）变量的名称不会有任何危害。实际上，这也是很流行的做法。

&emsp;&emsp;使用 for 循环与使用 while 循环相比较还有另外一个优势：更简短，从而增强了可读性。

&emsp;&emsp;下面是另外一种对局部变量的作用域进行最小化的循环做法：

```java
for (int i = 0, n = expensiveComputation(); i < n; i++) {
    ... // Do something with i;
}
```

&emsp;&emsp;关于这种做法要关注的事项是，它有两个循环变量 i 和 n，它们都具有完全正确的作用域。第二个变量 n 用于存储第一个变量的极限，从而避免了每次迭代中冗余计算的成本。通常，如果循环测试中涉及方法的调用，并且保证在每次迭代时返回相同的结果，则应使用这种习惯做法。

&emsp;&emsp;最后一种将局部变量的作用域最小化的方法时**使方法【体尽可能】小而集中** ，如果把两个操作（activity）合并到同一个方法中，与其中一个操作相关的局部变量就有可能会出现在执行另一个操作的代码范围之内。为了防止这种情况发生，只要把这个方法分成两个，每个方法各执行一个操作。

## for-each 循环优先于传统的 for 循环

&emsp;&emsp;如第 45 项所述，某些任务最好用流（stream）完成，其他任务最好用 Iterator 完成。这是一个传统的 for 循环迭代集合：

```java
// Not the best way to iterate over a collection!
for (Iterator<Element> i = c.iterator(); i.hasNext(); ) {
    Element e = i.next();
    ... // Do something with e
}
```

&emsp;&emsp;这是使用传统的 for 循环遍历数组【的做法】：

```java
// Not the best way to iterate over an array!
for (int i = 0; i < a.length; i++) {
    ... // Do something with a[i]
}
```

&emsp;&emsp;这些做法比 while 循环（第 57 项）更好，但是它们也并不完美。迭代器和索引变量都会造成一些混乱————你所需要的都是【其中的】元素。而且，它们也代表着出错的可能。迭代器在每个循环中出现三次，索引变量出现四次，这使得你有很多机会使用错误的变量。一旦出错，就无法保证编译器能够发现错误。最后，这两种循环是完全不一样的，不必去注意容器的类型，也不必添加（轻微（minor））麻烦来改变这种类型（drawing unnecessary attention to the type of the container and adding a (minor) hassle to changing that type）。

&emsp;&emsp;for-each 循环（官方称为“增强语句”）解决了所有的这些问题。它通过隐藏迭代器或索引变量来避免【造成】混乱和出错的机会。由此产生的习惯【用法】同样适用于集合和数组，简化了将容器的实现类型从一个切换到另一个的过程：

```java
// The preferred idiom for iterating over collections and arrays
for (Element e : elements) {
    ... // Do something with e
}
```

&emsp;&emsp;当你看到冒号(:)时，可以把它读作“在……里面”。因此上面的循环可以读作：“对于元素中的每个元素 e”。利用 for-each 循环不会有性能损失，甚至用于数组也一样：他们生成的代码与你手工编写的代码基本相同。

&emsp;&emsp;在对多个集合进行嵌套式迭代时，for-each 循环对于传统的 for 循环的这种优势还会更加明显。下面就是人们在试图做嵌套遍历时会犯的错误：

```java
// Can you spot the bug?
enum Suit { CLUB, DIAMOND, HEART, SPADE }
enum Rank { ACE, DEUCE, THREE, FOUR, FIVE, SIX, SEVEN, EIGHT, NINE, TEN, JACK, QUEEN, KING }
...
static Collection<Suit> suits = Arrays.asList(Suit.values());
static Collection<Rank> ranks = Arrays.asList(Rank.values());
List<Card> deck = new ArrayList<>();
    for (Iterator<Suit> i = suits.iterator(); i.hasNext(); )
        for (Iterator<Rank> j = ranks.iterator(); j.hasNext(); )
            deck.add(new Card(i.next(), j.next()));
```

&emsp;&emsp;如果之前没有发现这个 BUG 也不必难过。许多专家级的程序猿偶尔也会犯这样的错误。问题在于，在迭代器对外部的集合（suits）调用了太多次的 next 方法了。它应该从外部的循环进行调用，以便每种花色调用一次，但它却是从内部循环调用，因此它是每张牌调用一次。在用完所有花色之后，循环就会抛出 NoSuchElementException 异常。

&emsp;&emsp;如果真的那么不幸，并且外部集合的大小是内部集合大小的几倍————可能因为它们是相同的集合————循环就会正常终止，但是不会完成你想要的工作。例如，下面是个考虑不周的尝试，要打印一对骰子的所有可能的滚法：

```java
// Same bug, different symptom!
enum Face { ONE, TWO, THREE, FOUR, FIVE, SIX }
...
Collection<Face> faces = EnumSet.allOf(Face.class);
for (Iterator<Face> i = faces.iterator(); i.hasNext(); )
    for (Iterator<Face> j = faces.iterator(); j.hasNext(); )
        System.out.println(i.next() + " " + j.next());
```

&emsp;&emsp;这个程序不会抛出异常，而是只打印 6 个重复的词（从“ONE ONE”到“SIX SIX”），而不是预计的 36 种组合。

&emsp;&emsp;为了修正这些示例中的 BUG，必须在外部循环的作用域中添加一个变量来保存外部元素：

```java
// Fixed, but ugly - you can do better!
for (Iterator<Suit> i = suits.iterator(); i.hasNext(); ) {
    Suit suit = i.next();
    for (Iterator<Rank> j = ranks.iterator(); j.hasNext(); )
        deck.add(new Card(suit, j.next()));
}
```

&emsp;&emsp;如果使用的是嵌套的 for-each 循环，这个问题就会完全消失。产生的代码就如你所希望的那样简洁：

```java
// Preferred idiom for nested iteration on collections and arrays
for (Suit suit : suits)
    for (Rank rank : ranks)
        deck.add(new Card(suit, rank));
```

&emsp;&emsp;遗憾的是，有三种常见的情况无法使用 for-each 循环：

- **破坏性过滤（Destructive filtering）** ————如果需要遍历集合，并删除选定的元素，就需要使用显式的迭代器，以便可以调用它的 remove 方法。你通常可以使用在 Java 8 中添加的 Collection 的 removeIf 方法来避免显式遍历。

- **转换** ————如果需要遍历列表或数组并替换其元素的部分或全部值，则需要列表的迭代器或数组索引才能替换元素的值。

- **并行迭代** ————如果需要并行地遍历多个集合，就需要显式地控制迭代器或者索引变量，以便所有迭代器或者索引变量都可以得到同步前移（就如上述关于有问题的牌和骰子的示例中所示范的那样）。

&emsp;&emsp;如果你发现自己处于上述任何一种情况，请使用普通的 for 循环并警惕此项中提到的陷阱。

&emsp;&emsp;for-each 循环不仅可以遍历集合和数组，还可以迭代实现 Iterable 接口的任何对象，该接口由单个方法组成。以下是接口的代码：

```java
public interface Iterable<E> {
    // Returns an iterator over the elements in this iterable
    Iterator<E> iterator();
}
```

&emsp;&emsp;如果你必须从头开始编写自己的 Iterator 实现，那么实现 Iterable 有点棘手，但是如果你正在编写一个代表一组元素的类型，你真的应该考虑让它实现 Iterable，即使你选择不让它实现 Collection 也是如此。这将允许你的用户使用 for-each 循环遍历你的类型，他们将永远感激你。

&emsp;&emsp;总之，for-each 循环在清晰度，灵活性和预防出错方面提供了超越传统 for 循环的优势，而且不会有性能损失。在使用中尽可能让 for-each 循环优先于 for 循环。

## 了解和使用类库

&emsp;&emsp;假设你希望产生位于 0 和某个上界之间的随机整数。面对这个常见的任务，许多程序猿会编写如下所示的方法：

```java
// Common but deeply flawed!
static Random rnd = new Random();
static int random(int n) {
    return Math.abs(rnd.nextInt()) % n;
}
```

&emsp;&emsp;这个方法看起来可能不错，但是却有三个缺点。第一个缺点是，如果 n 是一个比较小的 2 的乘方，经过一段相当短的周期之后，它产生的随机序列就会重复。第二个缺点是，如果 n 不是 2 的乘方，那么平均起来，有些数会比其他的数出现得更为频繁。如果 n 比较大，这个影响就会相当的明显。这可以通过下面的程序直观地体现出来，它会产生一百万个指定范围内的随机数，并打印出有多少个数字落在随机数取值范围的前半部分：

```java
public static void main(String[] args) {
    int n = 2 * (Integer.MAX_VALUE / 3);
    int low = 0;
    for (int i = 0; i < 1000000; i++)
        if (random(n) < n/2)
            low++;
    System.out.println(low);
}
```

&emsp;&emsp;如果 random 方法工作正常的话，这个程序打印出来的数将接近一百万的一半，但是如果真正运行这个程序，就会发现它打印出来的数接近于 666666.由 random 方法产生的数字有 2/3 落在随机数取值范围的前半部分。

&emsp;&emsp;random 方法的第三个缺点是，在极少数情况下，它的失败是灾难性的，返回一个落在指定范围之外的数。之所以如此，是因为这个方法试图通过调用 Math.abs，将 rnd.nextInt()返回的值映射为一个非负整数 int。假如 nextInt()返回 Integer.MIN_VALUE，那么 Math.abs 也会返回 Integer.MIN_VALUE，假设 n 不是 2 的乘方，那么取模操作符（%）将返回一个负数。这几乎肯定会使程序失败，而且这种失败很难重现。

&emsp;&emsp;为了编写能修正这三个缺点的 random 方法，有必要了解关于伪随机数生成器、数论和 2 的求补算法的相关知识。幸运的是，你并不需要自己来做这些工作————已经有现成的成果可以为你所用。它被称为 Random.nextInt(int)，你无需关心它如何完成其工作的细节（如果你有强烈的好奇心，可以研究它的文档或者源代码）。具有算法背景的高级工程师已经花了大量的时间来设计、实现和测试这个方法，然后经过这个领域中的专家的审查，以确保它的正确性。然后，标准类库经过 Beta 测试、发行和将近二十年的成千上万程序猿的广泛使用。在这个方法中还没有发现过缺陷，但是，如果将来发现有缺陷，在下一个发行版本中就会修正这些缺陷。**通过使用标准类库，可以充分利用这些编写标准类库的专家的知识，以及在你之前的其他人的使用经验** 。

&emsp;&emsp;从 Java 7 开始，你不应再使用 Random。对于大多数的用法，**选择的随机数生成器现在【首选】是 ThreadLocalRandom** 。它产生更高质量的随机数，而且速度非常快。在我的机器上，它比 Random 快 3.6 倍。对于 fork 连接池和并行流，请使用 SplittableRandom。

&emsp;&emsp;使用这些类库的第二个好处是，不必浪费时间为那些与工作不太相关的问题提供特别的解决方案。就像大多数程序猿一样，应该把时间花在应用程序上，而不是底层的细节上。

&emsp;&emsp;使用标准类库的第三个好处是，它们的性能往往会随着时间的推移而不断提高，无需你做任何努力。因为许多人在使用它们，被当作工业标准在使用，所以，提供这些标准类库的组织有强烈的动机要使它们运行得更快。这些年来，许多 Java 平台类库已经被重新编写了，有时候是重复编写，从而导致性能上有了显著的提高。

&emsp;&emsp;使用库的第四个优点是，它们往往会随着时间的推移而获得【更多的】功能。如果某个类库缺少了某些东西，开发人员社区就会把这些缺点告示出来（the developer community will make it known），并且可能会在后续版本中添加缺少的功能。

&emsp;&emsp;使用标准类库的最后一个好处是，可以使自己的代码融入主流，这样的代码更易容阅读、更容易维护、更容易被大多数的开发人员重用。

&emsp;&emsp;既然有那么多的优点，使用标准类库机制而不选择专门的实现，这显然是符合逻辑的，然而还是有相当一部分的程序猿没有这样做。为什么呢？可能它们并不知道有这些类库机制的存在。**每个主要版本的库中都添加了许多功能，并且可以随时了解这些新增内容** 。每次 Java 平台有重要的发行版本时，会有一个网页说明新的特性。这些网页值得仔细地读一读\[Java8-feat, Java9-feat\]。为了强调这一点，假设你想编写一个程序来打印命令行中指定的 URL 的内容（这大致与 Linux curl 命令相同）。在 Java 9 之前，这段代码有点乏味，但在 Java 9 中，transferTo 方法被添加到 InputStream 中。以下是使用此新方法执行此任务的完整程序：

```java
// Printing the contents of a URL with transferTo, added in Java 9
public static void main(String[] args) throws IOException {
    try (InputStream in = new URL(args[0]).openStream()) {
        in.transferTo(System.out);
    }
}
```

&emsp;&emsp;这些标准类库机制太庞大了，以至于不可能去学习所有的文档\[Java9-api\]，但是**每个程序猿都应该熟悉 java.lang、java.util 和 java.io，以及它们的子包** 。可以根据需要获取其他类库的知识。总结类库的技巧超出了本项的范围，这些技巧多年来一直在增长。

&emsp;&emsp;有几个类库特别值得一提。集合框架和流类库（第 45 项-第 58 项）应该是每个程序猿的基本工具包的一部分，也包括 java.util.concurrent 中的并发实用工具。这个包即包含高级别的并发工具来简化多线程的编程任务，还包含低级别的并发类型，允许专家们自己编写更高级的并发抽象。第 80 和 81 项讨论了 java.util.current 的高级部分。

&emsp;&emsp;有些情况下，一个类库工具并不能满足你的需要。你的需求越是特殊，这种情形就越有可能发生。虽然你的第一个念头应该是使用标准类库，但是，如果你在观察了它们在某些领域所提供的功能之后，确定它不能满足需要，那么就使用替代实现。任何有限的类库集提供的功能总是存在遗漏。如果你无法在 Java 平台库中找到所需要的内容，那么你的下一个选择应该是查看高质量的第三方库，例如 Google 优秀的开源 Guava 库\[Guava\]。如果你在任何适当的类库中都找不到所需要的功能，你可能只能自己实现，别无选择。

&emsp;&emsp;总而言之，不要重新发明轮子。如果你需要做的事情看起来是十分常见的，有可能类库中已经有某个类完成了这样的工作。如果确实是这样，就使用它；如果你不知道是否存在这样的类，就去查一查。一般而言，类库的代码可能比你自己编写的代码更好一些，并且会随着时间的推移不断改进。这并不是在影射你作为一只程序猿的能力。从经济角度的分析表明：类库代码受到的关注远远超过大多数普通程序猿在同样的功能上所能给予的投入。

## 如果需要精确的答案，请避免使用 float 和 double

&emsp;&emsp;float 和 double 类型主要是为了科学计算和工程计算而设计的。它们执行*二进制浮点运算（binary floating-point arithmetic）*，这是为了在广泛的数值范围上提供较为精确为快速的近似计算而精心设计的。然而，它们并没有提供完全精确的结果，所以不应该被用于需要精确结果的场合。**float 和 double 类型尤其不适合用于货币计算** ，因为要让一个 float 或者 double 精确地表示 0.1（或者 10 的任何其他负数次方值）是不可能的。

&emsp;&emsp;例如，假设你口袋中有$1.03，花掉了 42¢ 之后还剩下多少钱呢？下面是一个简单的程序片段，来回答这个问题：

```java
System.out.println(1.03 - 0.42);
```

&emsp;&emsp;遗憾的是，它打印出来的是 0.6100000000000001。这并不是个例。假设你的口袋里面有$1，你买了 9 个垫圈，每个为 10¢。那么你应该找回多少零钱呢？

```java
System.out.println(1.00 - 9 * 0.10);
```

&emsp;&emsp;根据这个程序片段，你得到的是\$0.09999999999999998。

&emsp;&emsp;你可能会认为，只要在打印之前将结果做一下舍入就可以解决这个问题，但遗憾的是，这种做法并不总是可行的。例如，假设你的口袋有$1，你看到货架上有一排美味的糖果，标价分别为10¢, 20¢, 30¢, 等等，一直到$1。你打算从标价为 10¢ 的糖果开始，每种买一颗，一直到不能支付货架上下一种价格的糖果位置，那么你可以买多少颗糖果？还会找回多少零钱？下面是一个简单的程序，用来解决这个问题：

```java
// Broken - uses floating point for monetary calculation!
public static void main(String[] args) {
    double funds = 1.00;
    int itemsBought = 0;
    for (double price = 0.10; funds >= price; price += 0.10) {
        funds -= price;
        itemsBought++;
    }
    System.out.println(itemsBought + " items bought.");
    System.out.println("Change: $" + funds);
}
```

&emsp;&emsp;如果你运行这个程序，你会发现你可以支付 3 颗糖果，而且还剩下0.3999999999999999。这个答案是不正确的！解决这个问题的正确办法是**是使用 BigDecimal、int 或者 long 进行货币计算** 。

&emsp;&emsp;下面的程序是上一个程序的简单翻版，它使用 BigDecimal 类型代替 double。请注意，使用的是 BigDecimal 的 String 构造函数而不是它的 double 构造函数。这是必须的，从而避免在计算中引入不准确的值\[Bloch05, Puzzle 2\]：

```java
public static void main(String[] args) {
    final BigDecimal TEN_CENTS = new BigDecimal(".10");
    int itemsBought = 0;
    BigDecimal funds = new BigDecimal("1.00");
    for (BigDecimal price = TEN_CENTS;
    funds.compareTo(price) >= 0;
    price = price.add(TEN_CENTS)) {
        funds = funds.subtract(price);
        itemsBought++;
    }
    System.out.println(itemsBought + " items bought.");
    System.out.println("Money left over: $" + funds);
}
```

&emsp;&emsp;如果运行这个修改过的程序，就会发现你可以支付 4 颗糖果，还剩下$0.00。这才是正确的答案。

&emsp;&emsp;然而，使用 BigDecimal 有两个缺点：与使用基本运算类型相比，这样做很不方便，而且很慢。如果你解决的是一个简单的问题，后一种缺点并不要紧，但是前一种缺点可能会让你很不舒服。

&emsp;&emsp;除了使用 BigDecimal 之外，还有一种办法是使用 int 或者 long，到底选用 int 或者 long 要取决于涉及数值的大小，同时要自己处理十进制小数点。在这个示例中，最明显的做法是以美分为单位进行计算，而不是以美元为单位。下面是这个例子的简单翻版，展示了这种做法：

```java
public static void main(String[] args) {
    int itemsBought = 0;
    int funds = 100;
    for (int price = 10; funds >= price; price += 10) {
        funds -= price;
        itemsBought++;
    }
    System.out.println(itemsBought + " items bought.");
    System.out.println("Cash left over: " + funds + " cents");
}
```

&emsp;&emsp;总而言之，对于任何需要精确答案的计算任务，请不要使用 float 或者 double。如果你想让系统来记录十进制小数点，并且不介意因为不使用基本类型而带来的不便，就请使用 BigDecimal。使用 BigDecimal 还有一些额外的好处，它允许你完全控制舍入，只要执行需要舍入的操作，就可以从八种舍入模式中进行选择。如果你使用合法的舍入行为执行业务计算，这就能派上用场。如果性能非常关键，并且你又不介意自己记录十进制小数点，而且涉及的数值又不会太大，使用 int 或者 long。如果数值范围没有超过 9 为十进制数字，就可以使用 int；如果不超过 18 位数字，就可以使用 long。如果数值可能超过 18 位数字，就必须使用 BigDecimal。

## 基本类型优先于装箱基本类型

&emsp;&emsp;Java 有一个类型系统由两部分组成，包含*基本类型（primitives）*，比如 int，double 和 boolean 和*引用类型（reference type）*，例如 String 和 List。每个基本类型都有一个对应的引用类型，称作*装箱基本类型（boxed primitive）*。装箱基本类型中对应于 int、double 和 boolean 的是 Integer、Double 和 Boolean。

&emsp;&emsp;如第 6 项所述，自动装箱（autoboxing）和自动拆箱（auto-unboxing）难以区分，但这并没有完全抹去基本类型和装箱类型之间的区别。这两种类型之间存在真正的差异，重要的是，你要清楚自己正在使用的是哪种类型，并且要在这两种类型之间谨慎地选择。

&emsp;&emsp;在基本类型和装箱基本类型之间有三个主要区别。第一，基本类型只有值，而装箱基本类型具有与它们的值不同的同一性（identities）。换句话说，两个装箱基本类型可以具有相同的值和不同的同一性。第二，基本类型只有功能完备的值，而每个装箱基本类型除了它对应基本类型的所有功能值之外，还有个非功能值：null。最后，基本类型通常比装箱基本类型更节省时间和空间。如果不小心，这三点区别就会让你陷入麻烦之中。

&emsp;&emsp;考虑下面这个比较器，它被设计用来表示 Integer 值的递增数字顺序。（回想一下，比较器的 compare 方法返回的数值到底是负数、零还是正数，要取决于它的第一个参数是小于、等于还是大于它的第二个参数。）在实践中你并不需要编写这个比较器，因为在 Integer 中已经实现了它的自然排序比较器，但它展示了一个值得关注的例子：

```java
// Broken comparator - can you spot the flaw?
Comparator<Integer> naturalOrder = (i, j) -> (i < j) ? -1 : (i == j ? 0 : 1);
```

&emsp;&emsp;这个比较器表面上看起来似乎不错，它可以通过许多测试。例如，它可以通过 Collection.sort 正确地给一个有一百万个元素的列表进行排序，无论这个列表中是否包含重复的元素。但是这个比较器有着很严重的缺陷。如果你要让自己信服，只要打印`naturalOrder.compare(new Integer(42), new Integer(42)).`的值。这两个 Integer 实例都表示相同的值(42)，因此这个表达式的值应该为 0，但它输出的却是 1，这表明第一个 Integer 的值大于第二个。

&emsp;&emsp;问题出在哪呢？naturalOrder 中的第一个测试工作得很好。对表达式 first < second 执行计算会导致被 first 和 second 引用的 Integer 实例被*自动拆箱（auto-unboxed）*，也就是说，它提取了它们的基本类型值。计算动作要检查产生的第一个 int 值是否小于第二个。但是假设答案是否定的。下一个测试就是执行计算表达式 first == second，它在两个对象引用上执行*同一性比较（identity comparison）*。如果 first 和 second 引用表示同一个 int 值的不同 Integer 实例，这个比较操作就会返回 false，比较器就会错误地返回 1，表示第一个 Integer 值大于第二个。**对装箱基本类型运用==操作符几乎总是错误的** 。

&emsp;&emsp;在实践中，如果你需要一个比较器来描述一个类型的自然顺序，你应该简单地调用 Comparator.naturalOrder（），如果你自己编写一个比较器，你应该使用比较器构造方法，或基本类型的静态比较方法（第 14 项）。这也就是说，你可以通过添加两个局部变量来修正这个问题，局部变量用来保存 Integer 拆箱之后的 int 值，并在这两个变量上执行所有的比较操作。这样可以避免大量的同一性比较：

```java
Comparator<Integer> naturalOrder = (iBoxed, jBoxed) -> {
    int i = iBoxed, j = jBoxed; // Auto-unboxing
    return i < j ? -1 : (i == j ? 0 : 1);
};
```

&emsp;&emsp;接下来，考虑这个令人愉快的小程序：

```java
public class Unbelievable {
    static Integer i;
    public static void main(String[] args) {
        if (i == 42)
            System.out.println("Unbelievable");
    }
}
```

&emsp;&emsp;它不是打印出 Unbelievable————但是它的行为也是很奇怪的。它在计算表达式（i==42 的时候抛出 NullPointerException 异常。问题在于，i 是一个 Integer，而不是 int，就像所有的对象引用域一样，它的初始值为 null。当程序计算表达式 i == 42 时，它就会将 Integer 和 int 进行比较。几乎在任何一种情况下，**当在一项操作中混合使用基本类型和装箱基本类型时，装箱基本类型就会自动拆箱** 。如果 null 对象引用被自动拆箱，就会得到一个 NullPointerException 异常。就如这个程序所示，它几乎可以在任何位置发生。修正这个问题很简单，声明 i 是一个 int 而不是 Integer 就可以了。

&emsp;&emsp;最后，考虑【原书】第 24 页第 6 项的这个程序：

```java
// Hideously slow program! Can you spot the object creation?
public static void main(String[] args) {
    Long sum = 0L;
    for (long i = 0; i < Integer.MAX_VALUE; i++) {
        sum += i;
    }
    System.out.println(sum);
}
```

&emsp;&emsp;这个程序运行起来比预计的要慢一些，因为它不小心将一个局部变量（sum）声明为是装箱基本类型 Long，而不是基本类型 long。程序编译起来没有错误或者警告，变量被反复地装箱和拆箱，导致明显的性能下降。

&emsp;&emsp;在本项中所讨论的这三个程序中，问题是一样的：程序猿忽略了基本类型和装箱基本类型之间的区别，并承受这些后果。在前面两个程序中，其结果是彻底的失败；在第三个程序中，则出现了服务器的性能问题。

&emsp;&emsp;那么什么时候应该使用装箱基本类型呢？它们有几个合理的用处。第一个是作为集合中的元素、键和值。你不能将基本类型放在集合中，因此你被迫使用装箱基本类型。这是一种更通用的特例。在参数化类型（第 5 章）中，必须使用装箱基本类型作为参数类型，因为 Java 语言不允许使用基本类型。例如，你不能将变量声明为 ThreadLocal\<int\>类型。因此必须使用 ThreadLocal\<Integer\>代替。最后，在进行反射的方法调用（第 65 项）时，必须使用装箱基本类型。

&emsp;&emsp;总之，当可以选择的时候，基本类型要优先于装箱基本类型。基本类型更加简单，也更加快速。如果必须使用装箱基本类型，要特别小心！**自动装箱减少了使用装箱基本类型的繁琐性，但是并没有减少它的风险** 。当程序使用==操作符比较两个装箱基本类型时，它做了个同一性比较，这几乎可以肯定不是你想要的。当程序进行涉及装箱和拆箱基本类型的混合类型计算时，它会进行拆箱，而且，**当你的程序做自动拆箱操作的时候，它可能会（can）抛出一个 NullPointerException 异常** 。最后，当程序装箱了基本类型值时，它会导致不必要的高开销。

## 如果其他类型更适合，则尽量避免使用字符串

&emsp;&emsp;字符串被用来表示文本，它在这方面也确实做得很好。因为在很多地方都可以用字符串，并且 Java 语言【对字符串】也支持得很好，因此将字符串用于除设计字符串之外的其他目的的自然倾向【也就是说，设计字符串本来是用来做某些事情的，但是除了这些事情之外，人们也会使用字符串】。本项就是讨论一些不应该使用字符串的情形。

&emsp;&emsp;**字符串不适合代替其他的值类型** 。当一段数据从文件、网络、或者键盘设备，输入到程序的时候，它通常以字符串的形式存在。有一种自然的倾向是让它继续保留这种形式，但是，只有当这段数据本质上确实是文本信息时，这种想法才是合理的。如果它是数值，就应该被转换为适当的数值类型，比如 int、float 或者 BigInteger 类型。如果它是一个“是-或-否”这种问题的答案，就应该被转换为适当的枚举类型或者 boolean 类型。如果存在适当的值类型，不管是基本类型还是对象引用，大多数应该使用这种类型。如果不存在这样的类型，就应该编写一个类型。虽然这条建议是显而易见的，但【这条建议】却经常被违反。

&emsp;&emsp;**字符串不适合代替枚举类型** 。正如在 34 项中讨论的，枚举类型比字符串更加适合用来表示枚举类型的常量。

&emsp;&emsp;**字符串不适合代替聚集类型** 。如果一个实体有多个组件，用一个字符串来表示这个实体通常是很不恰当的，例如，下面这行代码来自真实的系统————标识符的名称已经被修改了，一边发生纠纷：

```java
// Inappropriate use of string as aggregate type
String compoundKey = className + "#" + i.next();
```

&emsp;&emsp;这种方法有许多缺点。如果用来分隔域的字符也出现在某个域中，就会出现混乱。为了访问单独的域，必须解析该字符串，这个过程非常慢，也很繁琐，还容易出错。你无法提供 equals、toString 或者 compareTo 方法，但是却被迫接受 String 提供的行为。更好的做法是，简单地编写一个类来描述这个数据集，通常是一个私有的静态成员类（第 24 项）。

&emsp;&emsp;**字符串也不适合代替能力（capabilities）** 。有时候，字符串被用于对某种功能进行授权访问。例如，考虑设计一个线程局部变量（thread-local variable）的机制。这个机制提供的变量在每个线程中都有自己的值。自从 Java 1.2 发行版本以来，Java 类库就有提供线程局部变量的机制，但在那之前，程序猿必须自己完成。几年前面对这样的设计任务时，有些人自己提出了同样的设计方案：利用客户端提供的字符串键，对每个线程局部变量的内容进行访问授权：

```java
// Broken - inappropriate use of string as capability!
public class ThreadLocal {
    private ThreadLocal() { } // Noninstantiable
    // Sets the current thread's value for the named variable.
    public static void set(String key, Object value);
    // Returns the current thread's value for the named variable.
    public static Object get(String key);
}
```

&emsp;&emsp;这种方法的问题在于，这些字符串键代表了一个共享的全局命名空间。要使这种方法可行，客户端提供的字符串键必须是唯一的：如果两个客户端各自决定为它们的线程局部变量使用同样的名称，它们实际上就无意中共享了这个变量，这样通常会导致两个客户端都失败。而且，安全性也很差。恶意的客户端可能有意地使用与另一个客户端相同的键，以便非法地访问其他客户端的数据。

&emsp;&emsp;要修正这个 API 并不难，只要用一个不可伪造的键（unforgeable key，有时被称为能力（capability））来代替字符串即可：

```java
public class ThreadLocal {
    private ThreadLocal() { } // Noninstantiable
    public static class Key { // (Capability)
        Key() { }
    }
    // Generates a unique, unforgeable key
    public static Key getKey() {
        return new Key();
    }
    public static void set(Key key, Object value);
    public static Object get(Key key);
}
```

&emsp;&emsp;虽然这解决了基于字符串的 API 的两个问题，但是你还可以做得更好。实际上不再需要静态方法，它们可以被代之以键（Key）中的实例方法，这样这个键就不再是键，而是线程局部变量了。此时，这个不可被实例化的顶层类也不再做任何实质性的工作，因此可以删除这个顶层类，并将内层的嵌套类命名为 ThreadLocal：

```java
public final class ThreadLocal {
    public ThreadLocal();
    public void set(Object value);
    public Object get();
}
```

&emsp;&emsp;这个 API 不是类型安全的，因为当你从线程局部变量得到它时，必须将值从 Object 转换成它实际的值。不可能使原始的基于 String 的 API 是类型安全的，要使基于 Key 的 API 是类型安全的也是很困难，但是，通过将 ThreadLocal 类泛型化（第 29 项），使这个 API 变成类型安全的就是很简单的事情了：

```java
public final class ThreadLocal<T> {
    public ThreadLocal();
    public void set(T value);
    public T get();
}
```

&emsp;&emsp;大致地提一下，这正是 java.util.ThreadLocal 提供的 API。除了解决了基于字符串的 API 的问题之外，与前面的两个基于键的 API 相比，它还更快速、更优雅。

&emsp;&emsp;总而言之，如果可以使用更加合适的数据类型，或者可以编写更加适当的数据类型，就应该避免使用字符串来表示对象。若使用不当，字符串会比其他的类型更加笨拙、更加不灵活、速度更慢，也更容易出错。经常被错误地用字符串来代替的类型包括基本类型、枚举类型和聚合类型。

## 注意字符串拼接的性能

&emsp;&emsp;字符串拼接操作符（+，string concatenation operator）是把多个字符串组合为一个字符串的便利途径。产生单独一行的输出，或者构造一个字符串来表示一个较小的、大小固定的对象，使用字符串拼接操作符是非常好的，但它不能缩放（but it does not scale）。**重复地使用字符串拼接操作符来拼接 n 个字符串，需要 n 的平方级的时间** 【意思是时间复杂度为 n^2 ？】。由于字符串是不可变的导致了这一令人遗憾的结果（ This is an unfortunate consequence of the fact that strings are immutable ）（第 17 项）。当两个字符串被拼接在一起的时候，它们的内容都要被拷贝。

&emsp;&emsp;例如，考虑下面的方法，它通过反复拼接每个 item 行，构造出一个代表 statement 的字符串。代码如下：

```java
// Inappropriate use of string concatenation - Performs poorly!
public String statement() {
    String result = "";
    for (int i = 0; i < numItems(); i++)
        result += lineForItem(i); // String concatenation
    return result;
}
```

&emsp;&emsp;如果 item 数量巨大，这个方法的执行时间就难以估算。**为了获得可以接受的性能，请使用 StringBuilder 代替 String** ，来存储构建的 statement：

```java
public String statement() {
    StringBuilder b = new StringBuilder(numItems() * LINE_WIDTH);
    for (int i = 0; i < numItems(); i++)
        b.append(lineForItem(i));
    return b.toString();
}
```

&emsp;&emsp;自 Java 6 以来，为了使字符串拼接更快，已经做了很多工作了，但两种方法的性能差异仍然是巨大的：如果 numItems 返回 100，并且 lineForItem 返回一个固定长度为 80 个字符的字符串，在我的机器上，第二种做法比第一种做法要块 6.5 倍。因为第一种做法的开销随 item 数量而呈平方级增加，第二种做法则是线性增加，所以，item 的数目越大，性能的差别会越显著。注意，第二种做法预先分配了一个足够大的 StringBuilder 来保存整个结果，即使使用了默认大小的 StringBuilder，它仍然比第一种方法快 5.5 倍。

&emsp;&emsp;原则很简单：**不要使用字符串拼接操作符来合并多个字符串** ，除非性能无关紧要。相反，应该使用 StringBuilder 的 append 方法。另一种方法是，使用一个字符数组，或者每次只处理一个字符串，而不是将它们组合起来。

## 接口优先于反射机制

&emsp;&emsp;核心反射机制：java.lang.reflect，提供对任意类的编程式访问（The core reflection facility, java.lang.reflect, offers programmatic access to arbitrary classes.）。给定一个 Class 对象，你可以获得 Constructor、Mtehod 和 Field 实例，分别代表了该 Class 实例所表示的类的构造器、方法和域。这些对象提供了通过编程的方式（programmatic）访问类的成员名称、域类型、方法签名等信息的能力。

&emsp;&emsp;而且，Constructor，Method 和 Field 实例使你能够通过*反射机制（reflectively）*操作它们的底层对等体：通过调用 Constructor，Method 和 Field 实例上的方法，可以构造底层类的实例、调用底层类的方法，并访问底层类中的域。例如，Method.invoke 使你可以调用任何类的的任何对象上的任何方法（遵从常规的安全限制）。反射机制（reflection）允许一个类使用另一个类，即使当前者被编译的时候后者根本还不存在。然而，这种能力也要付出代价：

- **丧失了编译时类型检查的好处** ，包括异常检查。如果程序企图用反射方式调用不存在的或者不可访问的方法，在运行时它将会失败，除非采取了特别的预防措施。

- **执行反射访问所需要的代码非常笨拙和冗长** 。编写这样的代码非常乏味，阅读起来也很困难。

- **性能损失** 。反射方法调用比普通方法调用慢了许多。具体慢了多少，这很难说，因为受到了多个因素的影响。在我的机器上，当反射完成时，调用一个没有输入参数、返回【类型为】int 的方法会慢 11 倍。

&emsp;&emsp;有一些复杂的应用程序需要反射。示例包括代码分析工具和依赖注入框架。即便是这样的后来工具也已经不再使用反射了，因为它的缺点是显而易见的。如果你对应用程序是否需要反射有任何疑问，那么可能是不需要。

&emsp;&emsp;**如果只是以非常有限的形式使用反射机制，虽然也要付出少许代价，但是可以获得许多好处** 。对于有些程序，它们必须用到在编译时无法获得的类，但是在编译时存在的适当的接口或者超类，通过它们可以引用这个类（第 64 项）。如果是这种情况，你可以**通过反射方式创建实例，然后通过它们的接口或者超类，以正常的方式访问这些实例** 。

&emsp;&emsp;例如，下面的程序创建了一个 Set<String>实例，它的类是由第一个命令行参数指定的。该程序把其余的命令行参数插入到这个集合中，然后打印该集合。不管第一个参数是什么，程序都会打印出余下的命令行参数，其中重复的参数会被消除掉。这些参数的打印顺序取决于第一个参数中指定的类。如果指定“java.util.HashSet”，显然这些参数就会以随机的顺序打印出来；如果指定“java.util.TreeSet”，则它们就会按照字母顺序打印出来，因为 TreeSet 中的元素是排好序的。相应代码如下：

```java
// Reflective instantiation with interface access
public static void main(String[] args) {
    // Translate the class name into a Class object
    Class<? extends Set<String>> cl = null;
    try {
        cl = (Class<? extends Set<String>>) // Unchecked cast!
        Class.forName(args[0]);
    } catch (ClassNotFoundException e) {
        fatalError("Class not found.");
    }
    // Get the constructor
    Constructor<? extends Set<String>> cons = null;
    try {
        cons = cl.getDeclaredConstructor();
    } catch (NoSuchMethodException e) {
        fatalError("No parameterless constructor");
    }
    // Instantiate the set
    Set<String> s = null;
    try {
        s = cons.newInstance();
    } catch (IllegalAccessException e) {
        fatalError("Constructor not accessible");
    } catch (InstantiationException e) {
        fatalError("Class not instantiable.");
    } catch (InvocationTargetException e) {
        fatalError("Constructor threw " + e.getCause());
    } catch (ClassCastException e) {
        fatalError("Class doesn't implement Set");
    }
    // Exercise the set
    s.addAll(Arrays.asList(args).subList(1, args.length));
    System.out.println(s);
}
private static void fatalError(String msg) {
    System.err.println(msg);
    System.exit(1);
}
```

&emsp;&emsp;尽管这个程序就像一个“小玩具”，但是它所演示的这种方法是非常强大的。这个玩具程序可以很容易地变成一个通用的集合测试器，通过侵入式地操作一个或者多个集合实例，并检查是否遵守 Set 接口的约定，以此来验证指定的 Set 实现。同样地，它也可以变成一个通用的集合性能分析工具。实际上，它所演示的这种足以实现一个成熟的*服务提供者框架（service provider framework）*（第 1 项）。绝大多数情况下，使用反射机制时需要的也正是这种方法。

&emsp;&emsp;这个示例演示了反射机制的两个缺点。第一，该示例可以在运行时生成 6 个不同的异常，如果不使用反射实例化，则所有这些异常都是编译时错误。（为了好玩，你可以通过传入适当的命令行参数使程序生成 6 个异常中的每一个【调皮！】）。第 2 个缺点是需要 25 行繁琐的代码才能从类的名称生成类的实例，而构造函数调用则可以整齐地放在 1 行上。通过捕获 ReflectiveOperationException 异常可以减少程序的代码长度，ReflectiveOperationException 是 Java 7 中引入的各种反射异常的超类。这两个缺点都局限于实例化对象的那部分代码。一旦对象被实例化，它与其他的 Set 实例就无法区分。在实际的程序中，通过使用这种限定的反射方法，绝大部分代码可以不受影响。

&emsp;&emsp;如果你编译此程序，你将获得未受检的强制转换警告。【出现】这个警告是合理的，因为强转为 Class<? extends Set<String>>才会成功【编译】，即使指定名称的类不是 Set 的一种实现，在这种情况下，程序在实例化类时会抛出 ClassCastException 异常。要了解有关压制警告的相关信息，请阅读第 27 项。

&emsp;&emsp;类对于在运行时可能不存在的其他类、方法或者域的依赖性，用反射法进行管理，这种用法是合理的，但是很少使用。如果你要编写一个包，并且它运行的时候必须依赖其他某个包的多个版本，这种做法可能就非常有用。这种做法就是，在所支持的包所需要的最小环境下对它进行编译，通常是最老的版本，然后以反射方式访问任何更加新的类或者方法。如果企图访问的新的类或者新的方法在运行时不存在，为了使这种方法有效你还必须采取适当的动作。所谓适当的动作，可能包括使用某种其他可替换的办法来达到同样的目的，或者使用简化的功能进行处理。

&emsp;&emsp;简而言之，反射机制是一种功能强大的机制，对于复杂系统中特定的编程任务，它是非常必要的，但它也有一些缺点。如果你编写的程序必须要与编译时未知的类一起工作，如果有可能，就应该仅仅使用反射机制来实例化对象，而访问对象时则使用编译时已知的某个接口或者超类。

## 谨慎地使用本地方法

&emsp;&emsp;Java Native Interface (JNI) 允许 Java 应用程序可以调用*本地方法（native method）*，所谓本地方法是指使用*本地程序设计语言（native programming languages）*（比如 C 或者 C++）来编写的方法。从历史上看，本地方法主要有三种用途。它们提供了“访问特定于平台的机制”的能力，比如【访问】注册表。它们还提供了访问遗留代码库的能力，从而可以访问遗留数据（legacy data）。最后，本地方法可以通过本地语言，编写应用程序中注重性能的部分，从而提高系统的性能。

&emsp;&emsp;使用本地方法来访问特定于平台的机制是合法的，但这这么做的必要性并不是很高（but it is seldom necessary）：随着 Java 平台的成熟，它提供了越来越多以前只有在宿主平台上才拥有的特性。例如，在 Java 9 中添加的进程 API，这个 API 提供了访问操作系统的进程的功能。当 Java 中没有可用的等效库时，使用本地方法来使用遗留代码也是合法的。

&emsp;&emsp;**使用本地方法来提高性能的这种做法并不提倡** 。在早期的发行版本中（在 Java 3 之前），这样做往往是很有必要的，但从那时起 JVM 就变得更快了。对于大多数任务，现在可以在 Java 中获得与之相当的性能。例如，当在 1.1 版中添加 java.math 时，BigInteger 依赖于用 C 编写的一个快速的多精度算术库。在 Java 3 中，BigInteger 在 Java 中重新实现，并仔细调整到比原来【依赖于】本地【库】实现【的版本】运行得更快的程度。

&emsp;&emsp;这个故事的一个令人遗憾的结论是 BigInteger 从那以后变化不大，除了 Java 8 中大数字的快速乘法。在那段时间，本机【代码】库的【优化】工作仍在继续，特别是 GNU 多精度算术库（GMP）。现在需要真正高性能多精度算术的 Java 程序猿通过本地方法\[Blum14\]使用 GMP 是合理的。

&emsp;&emsp;使用本地方法具有严重的缺点。由于本地语言是不安全的（第 50 项），使用本地方法的应用程序不再能免受内存损坏错误的影响。由于本地语言比 Java 更依赖于平台，因此使用本地方法的程序不再是可自由移植的。它们【使用本地方法的应用程序】也很难调试。如果你不小心，本地方法可能会降低性能，因为垃圾收集器无法自动化，甚至无法跟踪本机内存使用情况（第 8 项），并且在进入和退出本地代码时，需要相关的固定开销。最后，需要与本地方法进行“耦合的代码（glue code）”编写起来单调乏味，并且难以阅读。

&emsp;&emsp;总而言之，在使用本地方法之前务必三思。极少数情况下会需要使用本地方法来提高性能。如果你必须要使用本地方法来访问底层的资源，或者本地代码库，也要尽可能少用本地代码，并且要进行全面测试。本地代码中的一个 BUG 就有可能破坏整个应用程序。

## 只针对异常的情况才使用异常

&emsp;&emsp;总有一天，如果你运气不好，你可能偶然发现一段看起来像这样的代码：

```java
// Horrible abuse of exceptions. Don't ever do this!
try {
    int i = 0;
    while(true)
        range[i++].climb();
} catch (ArrayIndexOutOfBoundsException e) {
}
```

&emsp;&emsp;这段代码有什么作用？看起来【这段代码的作用】并不明显，这就是不使用它的原因（第 67 项）。事实证明，这是一种用于循环遍历数组元素的非常有毛病的构想。当这个无限循环在尝试访问数组边界外的第一个数组元素时，用抛出（throw）、捕获（catch）、忽略 ArrayIndexOutOfBoundsException 异常的手段来达到终止无限循环的目的。假定它与数组循环的标准模式是等价的，对于任何一只 Java 程序猿来说，下面的标准模式一看就会明白：

```java
for (Mountain m : range)
    m.climb();
```

&emsp;&emsp;那么，为什么有人会优先使用基于异常的模式，而不是行之有效的模式呢？这是被误导了，他们企图利用 Java 的错误判断机制来提高性能，因为 VM 对每次数组访问都要检查越界情况，所以他们认为正常的循环终止测试被编译器隐藏了，但在 for-each 循环中仍然可见，这无疑是多余的，应该避免。这种想法有三个错误：

- 因为异常机制的设计初衷是用于不正常的情形，所以很少会有 JVM 实现试图对它们进行优化，使得与测试时显示的一样快速。

- 将代码放在 try-catch 块中会阻止 JVM 实现可能要执行的某些优化。

- 对数组进行遍历的标准模式并不会导致冗余的检查。有些 JVM 实现会将它们优化掉。

&emsp;&emsp;实际上，基于异常的模式比标准模式要慢得多。在我的机器上，对于一个有 100 个元素的数组，基于异常的模式比标准模式慢了 2 倍。

&emsp;&emsp;基于异常的循环模式不仅模糊了代码的意图，降低了它的性能，而且它还不能保证正常工作。如果循环中存在 BUG，那么使用异常控制流会掩盖BUG，从而使调试过程变得非常复杂。假设循环体中的计算【过程】调用一个方法，该方法对一些不相关的数组执行越界访问。如果使用合理的循环模式，这个 BUG 会产生未被捕捉的异常，从而导致线程立即结束，产生完整地堆栈跟踪【信息】。如果使用这个被误导的基于异常的循环模式，与这个 BUG 相关的异常就会被捕捉到，并且被错误地解释为正常的循环终止条件。

&emsp;&emsp;这个例子的教训很简单：**顾名思义，异常应该只用于异常的情况下；它们永远不应该用于控制正常的【代码执行】流程** 。更一般地说，应该优先使用标准的、容易理解的模式，而不是那些声称可以提供更好性能的、弄巧成拙的方法。即使真的能够改进性能，面对平台实现的不断改进，这种模式的性能优势也不可能一直保持。然而，由这种过度聪明的模式带来的微妙的 BUG，以及维护的痛苦却依然存在。

&emsp;&emsp;这条原则对于 API 设计也有启发。**设计良好的 API 不应该强迫它的客户端为了控制正常的流程而使用异常** 。如果类具有“状态依赖（state-dependent）”的方法，即只有在特定的不可预知的条件下才可以被调用的方法，这个类往往也应该有个单独的“状态测试（state-testing）”方法，即指示是否可以调用这个状态相关的方法。例如，Iterator 接口有一个“状态依赖”的 next 方法，和相应的状态测试方法 hasNext。这使得利用传统的 for 循环（以及 for-each 循环，在这里，是在内部使用 hasNext 方法）对集合使用迭代的标准模式成为可能：

```java
for (Iterator<Foo> i = collection.iterator(); i.hasNext(); ) {
    Foo foo = i.next();
    ...
}
```

&emsp;&emsp;如果 Iterable 缺少 hasNext 方法，客户端将被迫改用下面的做法：

```java
// Do not use this hideous code for iteration over a collection!
try {
Iterator<Foo> i = collection.iterator();
    while(true) {
        Foo foo = i.next();
        ...
    }
} catch (NoSuchElementException e) {
}
```

&emsp;&emsp;这应该非常类似于本项刚开始对数组进行迭代的例子。除了代码繁琐且令人误解之外，这个基于异常的模式可能执行起来也比标准模式更差，并且还可能掩盖系统中其他不相关部分的 BUG。

&emsp;&emsp;另一种提供单独的状态测试方法的做法是让状态依赖的方法返回空的 optional（第 55 项），或者如果它不能执行所需要的计算，那么就可以返回一个可识别的值，比如 null。

&emsp;&emsp;以下是一些指导原则，可以帮助你在“状态测试方法”、option 或可识别的返回值之间进行选择。如果对象将在缺少外部同步的情况下被并发访问，或者可被外界改变状态，必须使用 option 或可识别的返回值，因为在调用“状态测试”方法和调用对应的“状态相关”方法的时间间隔中，对象的状态可能会发生变化。如果单独的“状态测试”方法必须重复“状态相关”方法的工作，从性能的角度考虑，就应该使用 optional 或者可被识别的返回值。如果其他方面都是等同的，那么“状态测试”则略优于可别识别的返回值。它提供了更好的可读性，对于使用不当的情形，可能更加易于检测和改正：如果忘了去调用状态测试的方法，状态相关的方法就会抛出异常，使这个 BUG 变得很明显；如果忘了去检查可识别的返回值，这个 BUG 就很难会被发现。对于返回 optional，这不是问题【意思就是，如果返回 optional 就没有上面那些问题。OS：optianal 大法好！】。

&emsp;&emsp;总而言之，异常（exception）是为了在异常情况下使用而设计的。不要将它们用于普通的控制流，也不要编写迫使它们这么做的 API。

## 对可恢复的情况使用受检异常，对编程错误使用运行时异常

&emsp;&emsp;Java 程序设计语言提供了是三种可抛出的结构（throwable）：_受检异常（checked exceptions）_，*运行时异常（ runtime exceptions）*和*错误（error）*。在程序猿之间就存在一些困惑：什么时候适合使用哪种可抛出的结构。虽然做决定的界限并不总是那么清晰，但还是有一些一般性的原则提供了强有力的指导。

&emsp;&emsp;在决定使用受检异常或者未受检异常时，主要的原则是：**如果期望调用者能够适当地恢复【到正常状态】，对于这种情况就应该使用受检异常** 。通过抛出受检异常，强迫调用者在一个 catch 子句中处理该异常，或者将它传播出去。因此，方法中声明要抛出的每个受检异常，都是对 API 用户的一种潜在的指示：与异常相关联的条件是调用这个方法的一种可能的结果。

&emsp;&emsp;API 的设计者让 API 用户面对受检的异常，以此强制用户从这个异常条件中恢复。用户可以忽视这样的强制要求，只需要捕获异常并忽略即可，但这往往不是个好办法(第 77 项)。

&emsp;&emsp;有两种未受检的可抛出结构：运行时异常和错误。在行为上两者是等同的：它们都是不需要也不应该被捕获的可抛出结构。如果程序抛出未受检的异常或者错误，往往就属于不可恢复的情形，继续执行下去有害无益。如果程序没有捕获到这样的可抛出结构，将会导致当前线程停止（halt），并出现适当的错误消息。

&emsp;&emsp;**用运行时异常来表明编程错误** 。大多数的运行时异常都表示*违反了前提条件（precondition violation）*。违反前提条件仅仅是指因为客户端 API 没有遵守 API 规范建立的约定。例如，数组访问的约定指明了数组的下标值必须在零和数组长度减 1 之间。ArrayIndexOutOfBoundsException 表明这个前提条件被违反了。

&emsp;&emsp;这个建议的一个问题是，你是正在处理的错误是否具有可恢复的条件，或者是一个编程错误并不总是很清楚（One problem with this advice is that it is not always clear whether you’re dealing with a recoverable conditions or a programming error）。例如，考虑资源耗尽的情况，这可能是由编程错误引起的，例如分配一个不合理的大型数组，或者是由于资源的真正短缺。如果资源耗尽是由于暂时短缺或暂时需求增加造成的，那么这种情况很可能是可以恢复的。有个问题是：API 设计人员判断【导致】资源耗尽的给定实例是否可能允许恢复。如果你认为某个条件可能允许恢复，请使用受检异常; 如果不是，请使用运行时异常。如果不清楚是否可以进行恢复，则使用未受检异常可能是最好的方法，原因如第 71 项中所述。

&emsp;&emsp;虽然 Java 语言规范并没有要求，但是按照惯例，错误往往被 JVM 保留用于表示资源不足、约束失败，或者其他使程序无法继续运行的条件。由于这已经是个几乎被普遍接受的惯例，因此最好不要再实现任何新的 Error 子类。因此，**你实现的所有未受检的可抛出结构都应该是 RuntimeException 的子类** （直接的或者间接的）。你不仅不应该定义 Error 的子类，而且对于 AssertionError 异常，你也不应该抛出它们【出现 AssertionError 异常的时候要当场处理，将这个异常扼杀在摇篮中！】。

&emsp;&emsp;要想定义一个可抛出结构，它不是 Exception、RuntimeException 或 Error 的子类，这也是有可能的。JSL 并没有直接规定这样的可抛出结构，而是隐式地指定了：从行为意义上讲它们等同于普通的受检异常（即 Exception 的子类，但不是 RuntimeException 的子类）。那么，什么时候应该使用这样的可抛出结构呢？总之，永远也不会用到。它与普通的受检异常相比没有任何益处，只会困扰使用 API 的用户。

&emsp;&emsp;API 设计者经常忘记异常是完全成熟（full-fledged）的对象【不成熟的对象长啥样，抽象类？接口？】，可以在异常中定义任何方法。此类方法的主要用途是提供捕获异常的代码，其中包含有关导致抛出异常的条件的相关信息。在没有这种方法的情况下，有一种已知的方法是：程序员通过解析异常的字符串进而发现附加信息。这是种非常糟糕的做法（第 12 项）。可抛出的类很少指定其字符串表示【的信息】的细节，因此字符串表示【的信息】可能在不同的实现、不同的发布版本中表示不同的信息。因此，解析异常的字符串【得到异常】表示【的信息】的代码可能是不可移植且脆弱的。

&emsp;&emsp;因为受检异常通常表明【具有】可恢复的条件，因此对它们来说，提供一个信息进而帮助调用者从异常情况中恢复的方法尤其重要。例如，假设由于资金不足而尝试使用礼品卡进行购买时，会抛出受检异常。该异常应该提供一种访问方法来查询【资金】缺口（shortfall）。这将使得调用者能够将金额转发给购物者。有关此话题的更多信息，请参阅第 75 项。

&emsp;&emsp;总而言之，对于可恢复的情况，使用受检异常；对于程序错误，则使用运行时异常。如果不知道使用哪种【异常】的时候，就抛出未受检的异常。不要定义既不是受检异常也不是运行时异常的任何可抛出结构。在你的受检异常中提供方法来帮助恢复【程序】。

## 同步访问共享的可变数据

&emsp;&emsp;关键字 synchronized 可以保证在同一时刻，只有一个线程可以执行某一个方法，或者某一个代码块。许多程序猿把同步的概念仅仅理解为一种*互斥的方式（mutual exclusion）*，即，当一个对象被一个线程修改的时候，可以阻止另一个线程观察到对象内部不一致的状态。按照这种观点，对象被创建的时候处于一致的状态（第 17 项），当有方法访问它的时候，它就被锁定了。这些方法观察到对象的状态，并且可能会引起状态转变（state transition），即把对象从一种一致的状态转换到另一种一致的状态。正确地使用同步可以保证没有任何方法会看到对象处于不一致的状态中。

&emsp;&emsp;这种观点是正确的，但它只说出了同步的一半意义。如果没有同步，一个线程的变化就不能被其他线程看到。同步不仅可以阻止一个线程看到对象处于不一致的状态之中，它还可以保证进入同步方法或者同步代码块的每个线程，都看到由同一个锁保护的之前所有的修改效果。

&emsp;&emsp;Java 语言规范保证读或者写一个变量是*原子的（atomic）*，除非这个变量的类型为 long 或者 double\[JLS, 17.4, 17.7\]。换句话说，读取一个非 long 或 double 类型的变量，可以保证返回的值是某个线程保存在该变量中的，即使多个线程在没有同步的情况下并发地修改这个变量也是如此。

&emsp;&emsp;你可能听说过，为了提高性能，在读写原子数据的时候，应该避免使用同步。这个建议是非常危险而错误的。虽然语言规范保证了线程在读取原子数据的时候，不会看到任意的数值，但是它并不保证一个线程写入的值对另一个线程将是可见的。**为了在线程之间进行可靠的通信，也为了互斥访问，同步是必要的** 。这主要是因为 Java 语言规范中的*内存模型（memory model）*，它规定了一个线程所做的变化何时以及如何变成对其他线程可见\[JLS, 17.4; Goetz06, 16\]。

&emsp;&emsp;如果对共享的可变数据的访问不能同步，其后果将非常可怕，即使这个变量是的读写是原子的。考虑下面这个在一个线程中将另一个线程终止（stop）的任务。Java 类库中提供了 Thread.stop 方法，但是这个方法在很久以前就不提倡使用了，因为它本质上是不安全的——使用它会导致数据遭到破坏。**不要使用 Thread.stop** 。要在一个线程终止另一个线程，建议的做法是让第一个线程轮询（poll）一个 boolean 域，这个域一开始为 false，但是可以通过第二个线程设置为 true，这样来表示第一个线程要终止自己。由于 boolean 域的读和写操作都是原子的，程序猿在访问这个域的时候不再使用同步。

```java
// Broken! - How long would you expect this program to run?
public class StopThread {
    private static boolean stopRequested;
    public static void main(String[] args) throws InterruptedException {
        Thread backgroundThread = new Thread(() -> {
            int i = 0;
            while (!stopRequested)
                i++;
        });
        backgroundThread.start();
        TimeUnit.SECONDS.sleep(1);
        stopRequested = true;
    }
}
```

&emsp;&emsp;你可能期待这个程序运行大约一秒钟左右，之后主线程将 stopRequested 设置为 true，致使后台线程的循环终止。但是在我的机器上，这个程序*永远（never）*不会终止：因为后台线程永远在循环！

&emsp;&emsp;这个问题在于，由于没有同步，就不能保证后台线程何时“看到”主线程对 stopRequested 的值所做的改变。没有同步，虚拟机将代码：

```java
while(!stopRequested)
    i++;
```

&emsp;&emsp;转变成这样：

```java
while(!stopRequested)
    while(true)
        i++;
```

&emsp;&emsp;这种优化称为*提升(hoisting)*，它正是 OpenJDK Server VM 所做的。结果是一个*活性失败（liveness failure）*：这个程序无法前进（the program fails to make progress）【无法继续往下执行的意思吗...】。修正这个问题的一种方式是同步访问 stopRequested 域。这个程序会如预期的一样在大约一秒钟左右终止：

```java
// Properly synchronized cooperative thread termination
public class StopThread {
    private static boolean stopRequested;
    private static synchronized void requestStop() {
        stopRequested = true;
    }
    private static synchronized boolean stopRequested() {
        return stopRequested;
    }
    public static void main(String[] args) throws InterruptedException {
        Thread backgroundThread = new Thread(() -> {
            int i = 0;
            while (!stopRequested())
                i++;
        });
        backgroundThread.start();
        TimeUnit.SECONDS.sleep(1);
        requestStop();
    }
}
```

&emsp;&emsp;注意写方法（requestStop）和读方法（stopRequest）都被同步了。只同步写方法还不够！**除非读和写操作都被同步，否则就无法保证同步会起作用** 。偶尔只能同步写入（或读取）的程序似乎可以在某些机器上运行，但在这种情况下，它表现出来的现象是具有欺骗性的。

&emsp;&emsp;StopThread 在同步方法中的动作即使没有同步也是原子的。换句话说，这些方法的同步只是为了它的通信效果，而不是为了互斥访问。虽然循环的每个迭代中的同步开销很小，还是有其他正确的替代方法，它更加简洁，性能也可能更好。如果 stopRequested 被声明为 volatile，第二种版本的 StopThread 中的锁就可以省略。虽然 volatile 修饰符不执行互斥访问，但它可以保证任何一个线程在读取该域的时候都将看到最近刚刚被写入的值：

```java
// Cooperative thread termination with a volatile field
public class StopThread {
    private static volatile boolean stopRequested;
    public static void main(String[] args) throws InterruptedException {
        Thread backgroundThread = new Thread(() -> {
            int i = 0;
            while (!stopRequested)
                i++;
        });
        backgroundThread.start();
        TimeUnit.SECONDS.sleep(1);
        stopRequested = true;
    }
}
```

&emsp;&emsp;在使用 volatile 的时候务必要小心。考虑下面的方法，假设它要产生序列号：

```java
// Broken - requires synchronization!
private static volatile int nextSerialNumber = 0;
public static int generateSerialNumber() {
    return nextSerialNumber++;
}
```

&emsp;&emsp;这个方法的目的是要确保每个调用都返回不同的值（只要不超过 2^32 次调用）。这个方法的状态只包含一个可原子访问的域：nextSerialNumber，这个域的所有可能的值都是合法的。因此，不需要任何同步来保护它的约束条件。然而，如果没有同步，这个方法仍然无法正常工作。

&emsp;&emsp;问题在于，自增操作符（++）不是原子的。它的 nextSerialNumber 域中执行两项操作：首先它读取值，然后写回一个新值，相当于原来的值再加 1。如果第二个线程在线程读取旧值并写回新值之间读取域，则第二个线程将看到与第一个线程相同的值并返回相同的序列号。这是\*安全性失败（safety failure）：程序会计算出错误的结果。

&emsp;&emsp;修复 generateSerialNumber 的一种方法是将 synchronized 修饰符添加到其声明中。这确保了多个调用之间不会【出现】交叉，并且每次调用该方法都会看到先前【执行的】所有调用的效果。一旦你这么做了，就可以并且应该从 nextSerialNumber 中删除 volatile 修饰符。为了让这个方法更可靠，要用 long 代替 int，或者在 nextSerialNumber 快要重叠时抛出异常。

&emsp;&emsp;最好还是遵循第 59 项中的建议，使用类 AtomicLong，它是 java.util.concurrent.atomic 的一部分。该软件包为基本类型的单个变量提供了无锁，线程安全的编程【方式】（This package provides primitives for lock-free, thread-safe programming on single variables）。虽然 volatile 只提供同步的通信效果，但这个包也提供了原子性。这正是我们想要的 generateSerialNumber，它可能比使用同步的版本更好：

```java
// Lock-free synchronization with java.util.concurrent.atomic
private static final AtomicLong nextSerialNum = new AtomicLong();
public static long generateSerialNumber() {
    return nextSerialNum.getAndIncrement();
}
```

&emsp;&emsp;避免本项中所讨论到的问题的最佳办法是不共享可变的数据。要么共享不可变的数据（第 17 项），要么压根不共享。换句话说，**将可变数据限制在单个线程中** 。如果采用这一策略，为它建立文档就很重要，以便该策略可以随着程序的发展而得到维护。深刻地理解正在使用的框架和类库也很重要，因为它们引入了你所不知道的线程。

&emsp;&emsp;让一个线程在短时间内修改一个数据对象，然后与其他线程共享，这是可以接受的，【因为】这个动作只是同步共享对象引用。其他线程只要不对该对象再次进行修改，那么其他线程不需要使用同步就能读取该对象（Other threads can then read the object without further synchronization, so long as it isn’t modified again）。这种对象被称作*事实上不可变的（effectively immutable）*\[Goetz06, 3.5.4\]。将这种对象的引用从一个线程传递到其他线程【的操作】称作*安全发布（safe publication）*\[Goetz06, 3.5.3\]。安全发布对象引用有许多种方法：你可以将它存储在 volatile 修饰的字段、final 字段、或者通过正常锁定访问的字段（a field that is accessed with normal locking）；或者你可以将它放到并发的集合中（第 81 项）。

&emsp;&emsp;简而言之，**当多个线程共享可变数据的时候，每个读或者写数据的线程都必须执行同步** 。如果没有同步，就无法保证一个线程所做的修改对另一个线程是可见的。未能同步共享可变数据会造成程序的*活性和安全性失败（liveness and safety failures）*。这样的失败是最难以调试的。它们可能是间歇性的，且与时间相关，程序的行为在不同的 VM 上可能根本不同。如果只需要线程之间的交互通信，而不需要互斥，volatile 修饰符就是一种可以接受的同步形式，但要正确地使用它可能需要一些技巧。

## 避免过度同步

&emsp;&emsp;第 78 项告诫我们缺少同步的危险性。本项则关注相反的问题。依据情况的不同，过度的同步可能会导致性能降低、死锁，甚至不确定的行为。

&emsp;&emsp;**为了避免活性失败和安全性失败，在一个被同步的方法或者代码块中，永远不要放弃对客户端的控制** 。换句话说，在一个被同步的区域内部，不要调用设计成要被覆盖的方法，或者是由客户端以函数对象的形式提供的方法（第 24 项）。从包含该同步区域的类的角度来看，这样的方法是*外来的（alien）*。这个类不知道该方法会做什么事情，也无法控制它。根据外来方法的作用，从同步区域中调用它会导致异常、死锁或者数据损坏。

&emsp;&emsp;为了对这个过程进行更具体的说明，来考虑下面的类，它实现了一个*可以观察（observable）*到的集合包装（set wrapper）。该类允许客户端在将元素添加到集合中时预定通知。这就是*观察者（Observer）*模式\[Gamma95\]。为了简洁起见，类在从集合中删除元素时没有提供通知，但要提供通知也是件很容易的事情。这个类是在第 18 项（原书 90 页）中可重用的 ForwardingSet 上实现的：

```java
// Broken - invokes alien method from synchronized block!
public class ObservableSet<E> extends ForwardingSet<E> {
    public ObservableSet(Set<E> set) { super(set); }
    private final List<SetObserver<E>> observers = new ArrayList<>();
    public void addObserver(SetObserver<E> observer) {
        synchronized(observers) {
            observers.add(observer);
        }
    }
    public boolean removeObserver(SetObserver<E> observer) {
        synchronized(observers) {
            return observers.remove(observer);
        }
    }
    private void notifyElementAdded(E element) {
        synchronized(observers) {
            for (SetObserver<E> observer : observers)
                observer.added(this, element);
        }
    }
    @Override public boolean add(E element) {
        boolean added = super.add(element);
        if (added)
            notifyElementAdded(element);
        return added;
    }
    @Override public boolean addAll(Collection<? extends E> c) {
        boolean result = false;
        for (E element : c)
            result |= add(element); // Calls notifyElementAdded
        return result;
    }
}
```

&emsp;&emsp;Observer 通过调用 addObserver 方法预订通知，通过调用 removeObserver 方法取消预订。在这两种情况下，这个*回调接口（callback）*的实例都会被传递给方法：

```java
@FunctionalInterface public interface SetObserver<E> {
    // Invoked when an element is added to the observable set
    void added(ObservableSet<E> set, E element);
}
```

&emsp;&emsp;该接口在结构上与 `BiConsumer<ObservableSet<E>，E>` 相同。我们选择定义自定义功能接口，因为接口和方法名称使代码更具有可读性，同时也因为接口可以演变为包含多个回调。也就是说，使用 BiConsumer 也可以得出合理的结论（第 44 项）。

&emsp;&emsp;如果只是粗略地检验一下，ObservableSet 会表现得很正常。例如，下面的程序打印出 0~99 的数字：

```java
public static void main(String[] args) {
    ObservableSet<Integer> set = new ObservableSet<>(new HashSet<>());
    set.addObserver((s, e) -> System.out.println(e));
    for (int i = 0; i < 100; i++)
        set.add(i);
}
```

&emsp;&emsp;现在我们来尝试一些更复杂点的例子。假设我们用一个 addObserver 调用来代替这个调用，用来替换的那个 addObserver 调用传递了一个打印 Integer 值的观察者，这个值被添加到该集合中，如果值为 23，这个观察者就要将自身删除：

```java
set.addObserver(new SetObserver<>() {
    public void added(ObservableSet<Integer> s, Integer e) {
        System.out.println(e);
        if (e == 23)
            s.removeObserver(this);
    }
    });
```

&emsp;&emsp;请注意，此调用使用匿名类实例代替上一次调用中使用的 lambda。那是因为函数对象需要将自身传递给 s.removeObserver，而 lambda 不能访问自己【在 lambda 里面无法使用 this 关键字】（第 42 项）。

&emsp;&emsp;你可能会期望这个程序会打印出 0~23 的数字，之后观察者会取消预定。实际上，它打印出 0~23 的数字之后抛出了 ConcurrentModificationException 异常。问题在于，当 notifyElementAdded 调用观察者的 added 方法时，它正处于遍历 observers 列表的过程中。added 方法调用观察集合的 removeObserver 方法，从而调用 observers.remove。现在我们有麻烦了。我们正企图在遍历列表的过程中，将一个元素从列表中删除，这是非法的。notifyElementAdded 方法中的迭代是在一个同步块中，可以防止并发的修改，但是无法防止迭代线程本身回调到观察的集合中，也无法防止修改它的 observers 列表。

&emsp;&emsp;现在我们要尝试一些比较奇特的例子：我们来编写一个试图取消预定的观察者，但是不直接调用 removeObserver，它用另一个线程的服务来完成。这个观察者使用了一个*executor service*（第 80 项）：

```java
// Observer that uses a background thread needlessly
set.addObserver(new SetObserver<>() {
    public void added(ObservableSet<Integer> s, Integer e) {
        System.out.println(e);
        if (e == 23) {
            ExecutorService exec = Executors.newSingleThreadExecutor();
            try {
                exec.submit(() -> s.removeObserver(this)).get();
            } catch (ExecutionException | InterruptedException ex) {
                throw new AssertionError(ex);
            } finally {
                exec.shutdown();
            }
        }
    }
});
```

&emsp;&emsp;顺便提一下，请注意，此程序在一个 catch【代码】块中捕获两种不同的异常类型。Java 7 中添加了这种临时叫作*多重 catch（multi-catch）*的工具。它可以极大地提高【代码的】清晰度并减小程序的大小，这些程序在响应多种异常类型时的行为是相同。

&emsp;&emsp;当我们运行这个程序的时候，我们没有遇到异常，而是遭遇了死锁。后台线程调用 s.removeObserver，它企图锁定 observers，但它无法获得该锁，因为主线程已经拥有该锁。在这期间，主线程一直在等待后台线程来完成对观察者的删除，这正是造成死锁的原因。

&emsp;&emsp;编写这个例子主要是用来示范的，因为观察者实际上没有理由使用后台线程，但这个问题却是真实的。从同步区域中调用外来的方法，在真实的系统中已经造成了许多死锁，例如 GUI 工具箱。

&emsp;&emsp;在前面的这两个例子中（异常和死锁），我们都还算辛运的。调用外来方法（added）时，同步区域（observers）所保护的资源处于一致的状态。假设当同步区域所保护的约束条件暂时无效时，你要从同步区域中调用一个外来方法。由于 Java 程序设计语言中的锁是*可重入的（reentrant）*，这种调用不会死锁。就像在第一个例子中一样，它会产生一个异常，因为调用线程已经有这个锁了，因此当该线程试图再次获得该锁时会成功，尽管概念上不相关的另一项操作正在该锁所保护的数据上进行着。这种失败的后果可能是灾难性的。从本质上说，这个锁没有尽到它的职责。可再重入锁简化了多线程的面向对象程序的构造，但是它们可能会将活性失败（liveness failure）变成安全性失败（safety failure）。

&emsp;&emsp;辛运的是，通过将外来方法的调用移出同步的代码块来解决这个问题通常并不太困难。对于 notifyElementAdded 方法，这还涉及给 observers 列表拍张“快照”，然后没有锁也可以安全地遍历这个列表了。经过这一修改，前面两个例子运行起来便再也不会出现异常或者死锁了：

```java
// Alien method moved outside of synchronized block - open calls
private void notifyElementAdded(E element) {
    List<SetObserver<E>> snapshot = null;
    synchronized(observers) {
        snapshot = new ArrayList<>(observers);
    }
    for (SetObserver<E> observer : snapshot)
        observer.added(this, element);
}
```

&emsp;&emsp;事实上，要将外来方法的调用移出同步的代码块，还有一种更好的方法。在 Java 类库中提供了一个*并发集合（concurrent collection）*（第 81 项），称为 CopyOnWriteArrayList，这是专门为此目的定制的。这是 List 的一种实现，相当于 ArrayList 的一种变体，通过重新拷贝整个底层数组，进而实现所有的修改操作。由于内部数组永远不会被修改，因此迭代不需要锁定，速度也非常快。如果大量使用，CopyOnWriteArrayList 的性能将大受影响，但是对于观察者列表来说却是很合适的，因为它们几乎不改动，并且经常被遍历。

&emsp;&emsp;如果这个列表改成使用 CopyOnWriteArrayList，就不必改动 ObservableSet 的 add 和 addAll 方法。下面是这个类的其余代码。注意其中并没有任何显示的同步。

```java
// Thread-safe observable set with CopyOnWriteArrayList
private final List<SetObserver<E>> observers = new CopyOnWriteArrayList<>();
public void addObserver(SetObserver<E> observer) {
    observers.add(observer);
}
public boolean removeObserver(SetObserver<E> observer) {
    return observers.remove(observer);
}
private void notifyElementAdded(E element) {
    for (SetObserver<E> observer : observers)
        observer.added(this, element);
}
```

&emsp;&emsp;在同步区域之外被调用的外来方法被称作*开放调用（open call）*\[Goetz06, 10.1.4\]。除了避免意外失败，开放调用还可以极大地增加并发性。外来方法的运行时长是不固定的。如果在同步区域内调用外来方法，其他线程对受保护资源的访问就会遭到不必要的拒绝。

&emsp;&emsp;**通常，你应该在同步区域内做尽可能少的工作** 。获得锁，检查共享数据，根据需要转换数据，然后释放锁。如果你必须要执行某个很耗时间的动作，则应该设法把这个动作移到同步区域的外面，而不违背第 78 项中的指导方针。

&emsp;&emsp;本项的第一部分是关于正确性的。接下来，我们要简单地讨论一下性能。虽然自从 Java 平台早期以来，同步的成本已经急剧下降了，但更重要的是，永远不要过度同步。在这个多核的时代，过度同步的实际成本并不是指获取锁所花费的 CPU 时间；而是争抢锁：这样就失去了并行的机会，以及因为需要确保每个核都有一个一致的内存视图而导致的延迟。过度同步的另一项潜在开销在于，它会限制 VM 优化代码执行的能力。

&emsp;&emsp;如果你正在编写一个可变类，你有两个选择：你可以省略所有同步并允许客户端在需要并发使用时从外部进行同步，或者你可以在内部进行同步，使类变成*线程安全（thread-safe）*的（第 82 项）。只有当你通过内部实现同步，并发性有很明显的提高时，才应选择后一个选项，而不是让客户端在外部锁定整个对象。java.util 中的集合（过时的 Vector 和 Hashtable 除外）采用前一种方法，而 java.util.concurrent 中的集合采用后者（第 81 项）。

&emsp;&emsp;在早期的 Java 中，许多类违反了这些指导方针。例如，StringBuffer 实例几乎总是被用于单个线程之中，而它们执行的却是内部同步。为此，StringBuffer 基本上都由 StringBuilder 代替，StringBuilder 只是一个非同步的 StringBuffer。同样，java.util.Random 中的线程安全伪随机数生成器被 java.util.concurrent.ThreadLocalRandom 中的非同步实现取代也是很大一部分原因。当你不确定的时候，就不要同步你的类，但是要在文档中注明它不是线程安全的。

&emsp;&emsp;如果你在内部同步了类，就可以使用不同的方法来实现高并发性，例如分拆锁（lock splitting）、分离锁（lock striping）和非阻塞（nonblocking）并发控制。这些方法都超出了本书的讨论范围，但是它们在其他地方有讨论过\[Goetz06, Herlihy08\]。

&emsp;&emsp;如果方法修改了静态域，并且有可能从多个线程调用该方法，则必须在内部对该域的访问进行同步（除非该类可以容忍具有不确定性的行为）。多线程客户端无法在此类方法上执行外部同步，因为不相关的客户端可以在不同步的情况下调用该方法。该字段本质上是一个全局变量，即使它是私有的，因为它可以由不相关的客户端读取和修改。第 78 项中方法 generateSerialNumber 使用的 nextSerialNumber 字段举例说明了这种情况。

&emsp;&emsp;简而言之，为了避免死锁和数据被破坏，千万不要从同步区域调用外来方法。更为一般地讲，要尽量限制同步区域内部的工作量。当你在设计一个可变类的时候，要考虑一下它们是否应该自己完成同步操作。在现在这个多核的时代，这比永远不要过度同步来得更重要。只有当你有足够的理由一定要在内部同步类的时候，才应该这么做，同时还应该将这个决定清楚地写到文档中(第 82 项)。

## executor、task 和 stream 优先于线程

&emsp;&emsp;本书的第一版包含简单的*工作队列（work queue）*的代码\[Bloch01, Item 49\]。这个类允许客户端将后台线程的异步处理工作排入队列。当不再需要这个工作队列时，客户端可以调用一个方法，让后台线程完成了已经在队列中的所有工作之后，优雅地终止自己。这个实现几乎就像个玩具，但即使如此，它还是需要一整页微妙、精致的代码，一不小心，就容易出现安全问题或者导致活性失败（liveness failure）。幸运的是，你不再需要编写这样的代码了。

&emsp;&emsp;到本书第二版出版时，java.util.concurrent 已添加到 Java 中。该软件包包含一个 Executor Framework，它是一个灵活的基于接口的任务执行工具。创建一个比本书第一版更好的工作队列只需要一行代码：

```java
ExecutorService exec = Executors.newSingleThreadExecutor();
```

&emsp;&emsp;以下是如何提交并执行 runnable:

```java
exec.execute(runnable);
```

&emsp;&emsp;下面是告诉 executor 如何优雅地终止（如果你没有这样做，很可能你的 VM 不会退出）：

```java
exec.shutdown();
```

&emsp;&emsp;你可以利用 executor service 完成更多的事情。例如，可以等待一项指定的任务【执行】完成（就项第 79 项，原书 319 页中的使用 get 方法一样），你可以等待一个任务集合中的任何任务或者所有任务完成（利用 invokeAny 或者 invokeAll 方法），你可以等待 executor service 终止（使用 awaitTermination 方法），你可以在完成任务时逐个检索任务结果（使用一个 ExecutorCompletionService），您可以安排任务在特定时间运行或定期运行（使用一个 ScheduledThreadPoolExecutor），等等。

&emsp;&emsp;如果想让不止一个线程来处理来自这个队列的请求，只要调用一个不同的静态工厂，这个工厂创建了一种不同的 executor service，称作*线程池（thread pool）*。你可以用固定或者可变数目的线程创建一个线程池。java.util.Executors 类包含了静态工厂，能为你提供所需的大多数 executor。然而，如果你想来点特别的，可以直接使用 ThreadPoolExecutor 类。这个类几乎允许你控制线程池每个功能的操作【阿里巴巴规范也是推荐使用这个类】。

&emsp;&emsp;为特定应用程序选择执行的程序服务可能很棘手。对于小的程序，或者轻载的服务器，使用 Executors.newCachedThreadPool 通常是个不错的选择，因为它不需要配置，并且一般情况下能够正确地完成工作。但是对于大负载的服务器来说，缓存的线程池就不是很好的选择了！在缓存的线程池中，被提交的任务没有排成队列，而是直接交给线程执行。如果没有线程可用，就创建一个新的线程。如果服务器负载得太重，导致了它所有的 CPU 都完全被占用了，当有更多的任务时，就会创建更多的线程，这样只会使情况变得更糟。因此，在大负载的产品服务器中，最好使用 Executors.newFixedThreadPool，它为你提供了一个包含固定线程数目的线程池，或者为了最大限度地控制它，就直接使用 ThreadPoolExecutor 类。

&emsp;&emsp;您不仅应该避免编写自己的工作队列，而且通常情况下也应该避免直接使用线程。当您直接使用线程时，线程既可以作为工作单元，也可以作为执行它的机制。在 executor Framework 中，工作单元和执行机制是分开的。抽象的关键是工作单元，也就是*任务（task）*。有两种任务：Runnable 及【功能】相近的 Callable（除了它会返回一个值并且可以抛出任意异常之外，它类似于 Runnable）。执行任务的通用机制是*executor service*。如果你从任务的角度来看问题，并让一个 Executor service 替你执行任务，您可以灵活地选择适当的执行策略以满足您的需求，并在需求发生变化时更改策略。从本质上讲，Executor Framework 所做的工作是执行，犹如 Collections Framework 所做的工作是聚集（aggregation）一样。

&emsp;&emsp;在 Java 7 中，Executor Framework 被扩展为支持[fork-join](https://www.ibm.com/developerworks/cn/java/j-lo-forkjoin/index.html)任务，这些任务由称为 fork-join 池的特殊 executor service 运行。由 ForkJoinTask 实例表示的 fork-join 任务可以拆分为较小的子任务，而包含 ForkJoinPool 的线程不仅处理这些任务，而且还彼此“窃取（steal）”任务以确保所有线程都保持忙碌，从而导致更高的 CPU 利用率，更高的吞吐量和更低的延迟。编写和调优 fork-join 任务很棘手。Parallel 流（第 48 项）写在 fork join 连接池之上，允许你轻松利用其性能优势，假设它们适合你手头上的任务。

&emsp;&emsp;对 Executor Framework 的完整处理超出了本书的范围，但感兴趣的读者可以参考《Java Concurrency in Practice》\[Goetz06\]。

## 并发工具优先于 wait 和 notify

&emsp;&emsp;本书的第一版专门用一项来【说明如何】正确使用 wait 和 notify\[Bloch01, 第 50 项\]。它的建议仍然有效，并在本项末尾进行了总结，但这个建议远不如以前那么重要。这是因为几乎没有理由再使用 wait 和 notify 了。自从 Java 5 以来，该平台提供了更高级别的并发工具，它们可以做一些你之前必须在 wait 和 notify 上手写代码来完成的各项工作。**鉴于正确地使用 wait 和 notify 比较困难，就应该使用更高级的并发工具来代替。**

&emsp;&emsp;java.util.concurrent 中更高级的工具分成三类：Executor Framework、并发集合（concurrent collections）、以及同步器（synchronizer），Executor Framework 在第 80 项已经简单介绍过了。并发集合和同步器将在本项中进行简单的阐述。

&emsp;&emsp;并发集合为标准的集合接口提供了高性能的并发实现，如 List、Queue 和 Map。为了提供高并发性，这些实现在内部自己内部同步（第 79 项）。因此，**并发集合中不可能排除并发活动；将它锁定只会使程序的速度变慢。**

&emsp;&emsp;因为您不能排除并发集合上的并发活动，所以您也不能以原子组合的方式对它们的方法进行调用（Because you can’t exclude concurrent activity on concurrent collections, you can’t atomically compose method invocations on them either）。因此有些集合接口已经通过*依赖状态的修改操作（state-dependent modify operations）*进行了扩展，它将几个基本操作合并到了单个原子操作中。事实证明，这些操作对并发集合非常有用，它们使用默认方法（第 21 项）添加到 Java 8 中相应的集合接口中。

&emsp;&emsp;例如，Map 的 putIfAbsent（key，value）方法插入键的映射（如果不存在）并返回与键关联的先前值【也就是被替换的值】，如果没有则返回 null。这样可以轻松实现线程安全的规范化映射。此方法模拟 String.intern 的行为：

```java
// Concurrent canonicalizing map atop ConcurrentMap - not optimal
private static final ConcurrentMap<String, String> map = new ConcurrentHashMap<>();
public static String intern(String s) {
    String previousValue = map.putIfAbsent(s, s);
    return previousValue == null ? s : previousValue;
}
```

&emsp;&emsp;事实上，你可以做得更好。ConcurrentHashMap 针对检索操作进行了优化，例如 get。因此，如果 get 表明有必要，最初只需调用 get，再调用 putIfAbsent：

```java
// Concurrent canonicalizing map atop ConcurrentMap - faster!
public static String intern(String s) {
    String result = map.get(s);
    if (result == null) {
        result = map.putIfAbsent(s, s);
        if (result == null)
            result = s;
    }
    return result;
}
```

&emsp;&emsp;ConcurrentHashMap 除了提供卓越的并发性之外，速度也非常快。在我的机器上，上面这个优化过的 intern 方法比 String.intern 速度快了超过六倍（但请记住，String.intern 必须采用一些策略来防止在长期存在的应用程序中泄漏内存）。并发集合使同步集合在很大程度上已经过时。例如，**优先使用 ConcurrentHashMap ，而不是 Collections.synchronizedMap** 。简单地用并发映射替换同步映射可以显著提高并发应用程序的性能。

&emsp;&emsp;有些集合接口已经通过*阻塞操作（blocking operations）*进行了扩展，它们会一直等待（或者*阻塞（block）*）直到可以成功执行为止。例如，BlockingQueue 扩展了 Queue 接口，并添加了包括 take 在内的几个方法，它们从队列中删除并返回头元素，如果队列为空，就等待。这样就允许将阻塞队列用于*工作队列（work queue）*，也被称为*生产者-消费者队列（producer-consumer queues）*，一个或者多个*消费者线程（consumer thread）*在工作队列中添加工作项目，一个或者多个*消费者线程（producer thread）*则从工作队列中将可用的工作项目取出队列并对它进行处理。正如你所期望的那样，大多数 ExecutorService 实现（包括 ThreadPoolExecutor）都使用 BlockingQueue（第 80 项）。

&emsp;&emsp;*同步器（Synchronizers）*是一些使线程能够等待另一个线程的对象，允许它们协调动作。最常用的同步器是 CountDownLatch 和 Semaphore。 不太常用的是 CyclicBarrier 和 Exchanger。最强大的同步器是 Phaser。

&emsp;&emsp;倒计时锁存器（Countdown latche）是一次性使用的屏障，允许一个或多个线程等待一个或多个其他线程执行某些操作。CountDownLatch 的唯一构造函数接受一个 int 参数，该参数是指在允许所有等待的线程继续之前必须在锁存器上调用 countDown 方法的次数。

&emsp;&emsp;在这个简单的基本类型上构建有用的东西是非常容易的。例如，假设您要构建一个简单的框架来定时执行一个操作的并发。这个框架包含仅仅只有一个方法，这个方法带有一个执行该动作的 executor，一个并发级别（表示要并发执行该动作的次数），以及表示该动作的 runnable。在计时器线程启动时钟【clock，翻译成计时会不会好一点】之前，所有工作线程都准备好自己要运行的操作。当最后一个工作线程准备好执行该动作时，timer 线程就“打响第一枪”，同时允许工作线程执行该动作。一旦最后一个工作线程执行完该动作，timer 线程就立即停止计时。直接在 wait 和 notify 之上实现这个逻辑至少来说会很混乱，而在 CountDownLatch 之上实现则相单简单：

```java
// Simple framework for timing concurrent execution
public static long time(Executor executor, int concurrency, Runnable action) throws InterruptedException {
    CountDownLatch ready = new CountDownLatch(concurrency);
    CountDownLatch start = new CountDownLatch(1);
    CountDownLatch done = new CountDownLatch(concurrency);
    for (int i = 0; i < concurrency; i++) {
        executor.execute(() -> {
            ready.countDown(); // Tell timer we're ready
            try {
                start.await(); // Wait till peers are ready
                action.run();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            } finally {
                done.countDown(); // Tell timer we're done
            }
        });
    }
    ready.await(); // Wait for all workers to be ready
    long startNanos = System.nanoTime();
    start.countDown(); // And they're off!
    done.await(); // Wait for all workers to finish
    return System.nanoTime() - startNanos;
}
```

&emsp;&emsp;注意这个方法使用了三个倒计数锁存器。第一个是 ready，工作线程用它来告诉 timer 线程它们已经准备好了。然后工作线程在第二个锁存器上等待，也就是 start。当最后一个工作线程调用 read.countDown 时，timer 线程记录下起始时间，并调用 start.countDown，并允许所有的工作线程继续进行。然后 timer 线程在第三个锁存器（即 done）上等待，直到最后一个工作线程运行完该动作，并调用 done.countDown。一旦调用这个，timer 线程就会苏醒过来，并记录下结束的时间。

&emsp;&emsp;还有一些细节值得注意。传递给 time 方法的 executor 必须允许创建至少与指定并发级别一样多的线程，否则这个测试就永远不会结束。这就是*线程饥饿死锁（thread starvation deadlock）*\[Goetz06, 8.1.1\]。如果线程捕捉到 InterruptedException，就会利用习惯用法 Thread.currentThread().interrupt()重新断言中断，并从它的 run 方法中返回。这样就允许 executor 在必要的时候处理终端，事实上也是如此。注意，这利用了 System.nanoTime()来给活动定时。**对于间歇性的定时，始终应该优先使用 System.nanoTime，而不是使用 System.currentTimeMillis** 。System.nanoTime 更加准确也更加精确，它不受系统的实时时钟的调整所影响。最后，请注意，此示例中的代码不会产生准确的计时，除非操作执行了大量工作，例如一秒钟或更长时间。准确的微基准测试是非常困难的，最好借助于 jmh\[JMH\]等专用框架来完成。

&emsp;&emsp;本项仅仅触及了并发工具的一些皮毛。例如，前面的例子中的那三个倒计数锁存器其实可以用一个 CyclicBarrier 或者 Phaser 实例来代替。这样产生的代码更加简洁，但是理解起来比较困难。

&emsp;&emsp;虽然你始终应该优先使用并发工具，而不是使用 wait 和 notify，但可能必须维护使用了 wait 和 notify 的遗留代码。wait 方法被用来使线程等待某些条件。它必须在同步区域内部被调用，这个同步区域将对象锁定在了调用 wait 方法的对象上。下面是使用 wait 方法的标准模式：

```java
// The standard idiom for using the wait method
synchronized (obj) {
    while (<condition does not hold>)
        obj.wait(); // (Releases lock, and reacquires on wakeup)
    ... // Perform action appropriate to condition
}
```

&emsp;&emsp;**始终应该使用 while 循环模式来调用 wait 方法；永远不要在循环之外调用 wait 方法** 。循环会在等待之前和之后测试条件【是否成立】。

&emsp;&emsp;在等待之前测试条件【是否成立】，当条件已经成立时就跳过等待，这对于确保*活性（liveness）*是必要的。如果条件已经成立，并且在线程等待之前，notify（或者 notifyAll）方法已经被调用，则无法保证该线程将会从等待中苏醒过来。

&emsp;&emsp;在等待之后测试条件【是否成立】，如果条件不成立的话就继续等待，这对于确保安全性（safety）是必要的。当条件不成立的时候，如果线程继续执行，则可能会破坏被锁保护的约束关系。当条件不成立的时候，下面有一些理由可以使一个线程苏醒过来：

- 另一个线程可能已经得到了锁，并且从一个线程调用 notify 那一刻起，到等待线程苏醒过来的这段时间中，得到锁的线程已经改变了受保护的状态。

- 条件并不成立的情况下，另一个线程可能意外地或者恶意地调用了 notify。在公有可访问的对象上等待，这些类实际上把自己暴露在了这种危险的境地中。公有可访问对象的同步方法中包含的 wait 都会出现这样的问题。

- 通知线程（notifying thread)在唤醒等待线程时可能会过度“大方”。例如，即使只有某一些等待线程的条件已经被满足，但是通知线程可能仍然调用 notifyAll。

- 在没有通知的情况下，等待线程也可能(但很少)会苏醒过来。这被称为\*伪唤醒（spurious wakeup）\[POSIX, 11.4.3.6.1; Java9-api\]。

&emsp;&emsp;一个相关的话题是，为了唤醒正在等待的线程，你应该使用 notify 还是 notifyAll（回忆一下，notify 唤醒的是某个正在等待的线程，假设有这样的线程存在，而 notifyAll 唤醒的则是所有正在等待的线程）。一种常见的说法是，你应该总是使用 notyfiAll。这是合理而保守的建议。它总会产生正确的结果，因为它可以保证你将唤醒所有需要被唤醒的线程。你可能也会唤醒其他一些线程，但是这不会影响程序的正确性。这些线程醒来之后，会检查它们正在等待的条件，如果发现条件并不满足，就会继续等待。

&emsp;&emsp;从优化的角度来看，如果可能在处于等待的所有线程都在等待相同的条件并且一次只有一个线程可以从条件变为 true 的时候受益【被唤醒】，则可以选择调用 notify 而不是 notifyAll。

&emsp;&emsp;即使前面的那些条件都满足了，也许还是有理由使用 notifyAll 而不是 notify。就好像把 wait 调用放在一个循环中，以避免在公有可访问对象上的意外或者恶意的通知一样，与此类似，使用 notifyAll 代替 notify 可以避免来自不相关线程的意外或者恶意的等待。否则，这样的等待会“吞掉”一个关键的通知，使真正的接受线程无限地等待下去。

&emsp;&emsp;简而言之，直接使用 wait 和 notify 就像用“并发汇编语言”进行编程一样，而 java.util.concurrent 则提供了更高级的语言。**没有理由在新代码中使用 wait 和 notify，即使有，也是极少的** 。如果你在维护使用了 wait 和 notify 的代码，务必确保始终是利用标准的模式从 while 循环内部调用 wait。一般情况下，你应该优先使用 notifyAll，而不是使用 notify。如果使用 notify，请一定要小心，以确保程序的活性（liveness）。

## 线程安全性文档化

&emsp;&emsp;当并发使用一个类的方法时，类的行为方式是该类与其客户端建立的约定的重要组成部分。如果这方面的内容你没有在类的文档中记录下来，使用这个类的用户将被迫做出假设。如果这些假设是错误的，这样得到的程序就可能缺少足够的同步（第 78 项）或者过度同步（第 79 项）。无论哪种情况，都可能导致严重的错误。

&emsp;&emsp;你可能听到过这样的说法：通过查看文档中是否出现 synchronized 修饰符，你可以确定一个方法是否是线程安全的。这种说法从几个方面来说都是错误的。在正常的操作中，Javadoc 并没有在它的输出中包含 synchronized 修饰符，是有理由的。**因为在一个方法中出现 synchronized 修饰符，这是个实现的细节，并不是 API 的一部分** 。它并不一定表明这个方法是线程安全的。

&emsp;&emsp;而且，“声明的时使用了 synchronized 修饰符就足以【代替】文档说明线程的安全性”的这种说法体现了【人们的】一种误解，即线程安全是全有或全无的属性。实际上，线程安全性有多种级别。**一个类为了可以被多个线程安全地使用，必须在文档中清楚地说明它所支持的线程安全的级别** 。下面的列表概括了线程安全性的几种级别。这份列表并没有涵盖所有的可能，而只是些常见的情形：

- **不可变的（immutable）** ——这个类的实例是不变的。所以，不需要外部的同步。这样的例子包括 String、Long 和 BigInteger（第 17 项）。

- **无条件的线程安全（Unconditionally thread-safe）** ——这个类的实例是可变的，但是这个类有着足够的内部同步，所以，它的实例可以被并发使用，无需任何外部同步。其例子包括 AtomicLong 和 ConcurrentHashMap。

- **有条件的线程安全（Conditionally thread-safe）** ——除了有些方法为进行安全的并发使用而需要外部同步之外，这种线程安全级别与无条件的线程安全相同。这样的例子包括 Collections.synchronized 包装返回的集合，它们的迭代器（iterator）要求外部同步。

- **非线程安全（not thread-safe）** ——这个类的实例是可变的。为了并发地使用它们，客户端必须利用自己选择的外部同步包围每个方法调用（或者调用序列）。这样的例子包括通用的集合实现，例如 ArrayList 和 HashMap。

- **线程对立的（thread-hostile）** ——这个类不能安全地被多个线程并发使用，即使所有的方法调用都被外部同步包围。线程对立的根源通常在于，没有同步地修改静态数据。没有人会有意地编写一个线程对立的类；这种类是因为没有考虑并发性而产生的后果。当发现类或者方法是线程对立的时候，通常会修复或者弃用它。如【原书】第 322 页所述，在没有内部同步的情况下，第 78 项中的 generateSerialNumber 方法将是线程对立的。

&emsp;&emsp;这些分类（除了线程对立的之外）初略对应于《Java Concurrency in Practice》一书中的*线程安全注解（thread safety annotation）*，分别是 Immutable、ThreadSafe 和 NotThreadSafe \[Goetz06, Appendix A\]。上述分类中无条件和有条件的线程安全类别都涵盖在 ThreadSafe 注解中了。

&emsp;&emsp;在文档中记录一个有条件的线程安全类要特别小心。你必须指明哪个调用序列需要外部同步，还要指明为了执行这些序列，必须获得哪个锁（极少的情况下是指多个锁）。通常情况下，这是指作用在实例自身上的那把锁，但也有例外。例如，Collections.synchronizedMap 的文档就有这样的说明：

> It is imperative that the user manually synchronize on the returned map when iterating over any of its collection views(当遍历任何被返回的 Map 的集合视图时，用户必须手工对它们进行同步):
>
> ```java
> Map<K, V> m = Collections.synchronizedMap(new HashMap<>());
> Set<K> s = m.keySet(); // Needn't be in synchronized block
> ...
> synchronized(m) { // Synchronizing on m, not s!
> for (K key : s)
>   key.f();
> }
> ```

&emsp;&emsp;如果没有遵循这样的建议，就可能造成不确定的行为。

&emsp;&emsp;类的线程安全性的描述通常属于类的文档注释，但具有特殊线程安全属性的方法应该在自己的文档注释中描述这些属性。没有必要说明枚举类型的不可变性。除非从返回类型来看已经很明显，否则静态工厂必须在文档中说明被返回对象的线程安全性，如 Collections.synchronizedMap（上述）所示。

&emsp;&emsp;当一个类承诺了“使用一个公有可访问的锁对象”时，就意味着允许客户端以原子的方式执行一个方法调用序列，但是，这种灵活性是要付出代价的。并发集合（如 ConcurrentHashMap）使用的哪种并发控制，并不能与高性能的内部并发控制相兼容。客户端还可以发起拒绝服务（denial-of service）攻击，它只需要超时地保持公有可访问锁即可。这可能是无意的，也可能是有意的。

&emsp;&emsp;为了避免这种拒绝服务攻击，应该使用一个*私有锁对象（private lock object）*来代替同步的方法（隐含着一个公有可访问锁）：

```java
// Private lock object idiom - thwarts denial-of-service attack
private final Object lock = new Object();
public void foo() {
    synchronized(lock) {
        ...
    }
}
```

&emsp;&emsp;因为这个私有锁对象不能被这个类的客户端程序所访问，所以它们不可能妨碍对象的同步。实际上，我们正是在应用第 15 项的建议，把锁对象封装在它所同步的对象中。

&emsp;&emsp;注意 lock 域被声明为 final 的。这样可以防止您无意中更改其内容，从而导致灾难性的非同步访问（第 78 项）。我们这是在应用第 17 项的建议，将 lock 域的可变性减到最小。**锁的域应该始终声明为 final** 。无论您使用普通的监视器锁（monitor lock）（如上所示）还是使用 java.util.concurrent.locks 包中的锁，都是如此。

&emsp;&emsp;这种私有锁对象的习惯用法只能用在*无条件（unconditionally）*的线程安全类上。有条件的线程安全类不能使用这种用法，因为它们必须在文档中说明：在执行某些方法调用序列时，它们的客户端程序必须获得哪把锁。

&emsp;&emsp;私有锁对象习惯用法特别适合用于继承的类（第 19 项）。如果这样的类要使用它的实例进行锁定，则子类可能很容易在无意中妨碍基类的操作，反之亦然。出于不同的目的而使用相同的锁，子类和基类可能会“相互绊住对方的脚”。这不只是一个理论意义上的问题。例如，这种现象在 Thread 类上就出现过\[Bloch05, Puzzle 77\]。

&emsp;&emsp;简而言之，每个类都应该利用字斟句酌的说明或者线程安全注解，清楚地在文档中说明它的线程安全属性。synchronized 修饰符与这个文档毫无关系。有条件的线程安全类必须在文档中指明“哪个方法调用序列需要外部同步，以及在执行这些序列的时候要获得哪把锁”。如果你编写的是无条件的线程安全类，就应该考虑使用私有锁对象来代替同步的方法。这样可以防止客户端程序和子类的同步干扰，让你能够在后续的版本中灵活地对并发控制采用更加复杂的方法。

## 慎用延迟初始化

&emsp;&emsp;*延迟初始化（Lazy initialization）*是延迟到需要域的值的时候才将它初始化的行为。如果永远不需要这个值，这个域就永远不会被初始化。这种方法既适用于静态域，也适用于实例域。虽然延迟初始化主要是一种优化，但它也可以用来打破类和实例初始化中的有害循环\[Bloch05, Puzzle 51\]。

&emsp;&emsp;就像大多数的优化一样，对于延迟初始化，最好的建议就是“除非绝对必要，否则就不要这么做”（第 67 项）。延迟初始化就像一把双刃剑。它降低了初始化类或者创建实例的开销，却增加了访问被延迟初始化的域的开销。根据延迟初始化的域最终需要初始化的比例、初始化这些域要多少开销，以及每个域多久被访问一次，延迟初始化（就像其他的许多优化一样）实际上降低了性能。

&emsp;&emsp;也就是说，延迟初始化有它的好处。如果域只在类的实例部分被访问，并且初始化这个域的开销很高，可能就值得进行延迟初始化。要确定这一点，唯一的办法就是测量类在用和不用延迟初始化时的性能差别。

&emsp;&emsp;当有多个线程时，延迟初始化是需要技巧的。如果两个或者多个线程共享一个延迟初始化的域，采用某种形式的同步是很重要的，否则就可能出现严重的 Bug（第 78 项）。本项中讨论的所有初始化方法都是线程安全的。

&emsp;&emsp;**在大多数情况下，正常的初始化要优先于延迟初始化** 。下面是正常初始化实例域的一个典型声明。注意其中使用了 final 修饰符（第 17 项）。

```java
// Normal initialization of an instance field
private final FieldType field = computeFieldValue();
```

&emsp;&emsp;**如果利用延迟初始化来破坏初始化循环，就要使用同步访问方法** ，因为它是最简单、最清晰的代替方法：

```java
// Lazy initialization of instance field - synchronized accessor
private FieldType field;
private synchronized FieldType getField() {
    if (field == null)
        field = computeFieldValue();
    return field;
}
```

&emsp;&emsp;这两种习惯用法（*正常的初始化*和*使用了同步访问方法的延迟初始化*）应用到静态域上时都不会更改，除了给域和访问方法的声明添加 static 修饰符之外。

&emsp;&emsp;**如果出于性能的考虑而需要对静态域使用延迟初始化，就使用 lazy initialization holder class 用法** 。这种用法保证了类要被用到的时候才会被初始化\[JLS, 12.4.1\]。如下所示：

```java
// Lazy initialization holder class idiom for static fields
private static class FieldHolder {
    static final FieldType field = computeFieldValue();
}
private static FieldType getField() { return FieldHolder.field; }
```

&emsp;&emsp;当 getField 方法第一次被调用时，它第一次读取 FieldHolder.field，导致 FieldHolder 类得到初始化。这种用法的魅力在于，getField 方法没有被同步，并且只执行访问一个域【的动作】，因此延迟初始化实际上并没有增加任何访问成本。现代的 VM 将在初始化该类的时候，同步域的访问，一旦这个类被初始化，VM 将修补代码，以便后续对该域的访问不会导致任何测试【测试是否已经初始化】或者同步。

&emsp;&emsp;**如果出于性能的考虑而需要对实例域使用延迟初始化，就使用双重检查模式（double-check idiom）**。这种模式避免了在域被初始化之后访问这个域时的锁定开销（第 79 项）。这种用法背后的思想是：两次检查域的值（因此名字叫*双重检查（double-check）*）：第一次检查时没有锁定，看看这个域是否被初始化了；第二次检查时有锁定。只有当第二次检查时表明这个域没有被初始化，该调用才会初始化该域。因为字段初始化后没有锁定，所以将字段声明为 volatile 是非常重要的（第 78 项）。下面就是这种习惯用法：

```java
// Double-check idiom for lazy initialization of instance fields
private volatile FieldType field;
private FieldType getField() {
    FieldType result = field;
    if (result == null) { // First check (no locking)
        synchronized(this) {
            if (field == null) // Second check (with locking)
                field = result = computeFieldValue();
        }
    }
    return result;
}
```

&emsp;&emsp;这段代码可能看起来似乎有些费解。尤其对于需要用到局部变量（result）可能有点不解。这个变量的作用是确保 field 只在已经被初始化的情况下读取一次。虽然这不是严格需要的，但是可以提升性能，并且因为在底层的并发编程中应用了一些标准，因此更加优雅。在我的机器上，上面的方法大约是没有使用局部变量版本的 1.4 倍。

&emsp;&emsp;虽然你也可以将双重检查模式应用于静态字段，但没有理由这样做：lazy initialization holder class idiom 是更好的选择。

&emsp;&emsp;双重检查模式的两个变量值得一提的是。有时候，你可能需要延迟初始化一个可以接受重复初始化的实例域。如果处于这种情况，就可以使用双重检查的习惯用法的一种变形，它省去了第二次检查。不用惊讶，没错，他就是*单重检查模式（single-check idiom）*。下面就是这样的一个例子。注意 field 仍然被声明为 volatile：

```java
// Single-check idiom - can cause repeated initialization!
private volatile FieldType field;
private FieldType getField() {
    FieldType result = field;
    if (result == null)
        field = result = computeFieldValue();
    return result;
}
```

&emsp;&emsp;本项中讨论的所有初始化方法都适用于基本类型的域，以及对象引用域。当双重检查模式（double-check idiom）或者单重检查模式（single-check idiom）应用到数值类型的基本类型域时，就会用 0 来检查这个域（这是数值类型基本变量的默认值），而不是 null。

&emsp;&emsp;如果你不在意是否*每个（every）*线程都重新计算域的值，并且域的类型为基本类型，而不是 long 或者 double 类型，就可以选择从单重检查模式的域声明中删除 volatile 修饰符。这种变体称之为*racy single-check idiom*。它以某些额外的初始化（每个访问该字段的线程最多【初始化】一次）为代价，在某些体系结构上加快了域访问的速度。这显然是一种特殊的方法，不适合在日常中使用。

&emsp;&emsp;简而言之，大多数的域应该正常地进行初始化，而不是延迟初始化。如果为了达到性能的目标，或者为了破坏有害的初始化循环，而必须延迟初始化一个域，就可以使用合适的延迟初始化方法。对于实例域，就使用双重检查模式（double-check idiom）；对于静态域，则使用 lazy initialization holder class idiom。对于可以接受重复初始化的实例域，也可以考虑使用单重检查模式（single-check idiom）。

## 不要依赖于线程调度器

&emsp;&emsp;当有多个线程可以运行时，由线程调度器（therad scheduler）来决定运行哪些线程，以及运行多长时间。任何一个合理的操作系统在做出这样的决定时，都会尽可能做到公正，但是所采用的策略却大相径庭。因此，编写良好的程序不应该依赖于这种策略的细节。**任何依赖于线程调度器来达到正确性或者性能要求的程序，很有可能都是不可移植的** 。

&emsp;&emsp;编写健壮，响应迅速的可移植程序的最佳方法是确保可运行线程的平均数量不会明显大于处理器数量。这使得线程调度程序几乎没有选择：它只能运行可运行的线程，直到它们不再可运行为止。即使在完全不同的线程调度策略下，程序的行为也不会有太大变化。请注意，可运行线程的数量与线程总数不同，后者可能要高得多。等待的线程是不可运行的。

&emsp;&emsp;保持可运行线程数量尽可能少的主要方法是，让每个线程做些有意义的工作，然后等待更多有意义的工作。**如果线程没有在做有意义的工作，就不应该运行** 。根据 Executor Framework（第 80 项），这意味着适当地规定了线程池的大小\[Goetz06, 8.2\]，并且使任务保持简短但不会太短【尽量让执行任务的时间短一点，但不能太短】，否则调度开销会影响到性能。

&emsp;&emsp;线程不应该一直处于*忙-等（busy-wait）*状态，即反复地检查一个共享对象，等待它的状态发生改变。除了使程序易受到调度器的变化影响之外，忙-等这种做法大大增加了处理器的负担，减少了其他进程可以完成的有用的工作量。作为一个极端的反面例子，考虑下面这个 CountDownLatch 的不正当的重新实现：

```java
// Awful CountDownLatch implementation - busy-waits incessantly!
public class SlowCountDownLatch {
    private int count;
    public SlowCountDownLatch(int count) {
        if (count < 0)
            throw new IllegalArgumentException(count + " < 0");
        this.count = count;
    }
    public void await() {
        while (true) {
            synchronized(this) {
                if (count == 0)
                    return;
            }
        }
    }
    public synchronized void countDown() {
        if (count != 0)
            count--;
    }
}
```

&emsp;&emsp;在我的机器上，当 1000 个线程在锁存器上等待时，SlowCountDownLatch 比 Java 的 CountDownLatch 慢了大约十倍。虽然这个例子看起来有点牵强，但是系统中有一个或者多个线程处于不必要的可运行状态，这种现象并不少见。性能和可移植性可能会受到影响。

&emsp;&emsp;如果某一个程序不能工作，是因为某些线程无法像其他线程那样获得足够的 CPU 时间，那么，**尽量不要试图通过调用 Thread.yield 来“修复”该程序** 。你可能好不容易成功地让程序能够工作，但这样得到的程序仍然是不可移植的。同一个 yield 调用在一个 JVM 实现上能提高性能，而在另一个 JVM 实现上却有可能会更差，在第三个 JVM 实现上则可能没有影响。**Thread.yield 没有可测试的语义（Thread.yield has no testable semantics.）** 。更好的解决办法是重新构造应用程序，以减少可并发运行的线程数量。

&emsp;&emsp;应用类似警告的一项相关的技术是调整线程的优先级。**线程优先级是 Java 平台上最不可移植的特征了** 。通过调整某些线程的优先级来改善应用程序的响应能力，这样做并非不合理，却是不必要的，也是不可移植的。通过调整线程的优先级来解决严重的活性问题是不合理的。在你找到并修正底层的真正原因之前，这个问题可能会再次出现。

&emsp;&emsp;总之，不要让应用程序的正确性依赖于线程调度器。由此产生的程序既不健壮，也不具有可移植性。以此推出结论，不要依赖 Thread.yield 或线程优先级。这些措施仅仅是对调度器做些暗示。线程优先级可以用来提高一个已经能正常工作的程序的服务质量，但永远不应该用来“修复”一个原本就不能工作的程序。

## 其他序列化优先于 Java 序列化

&emsp;&emsp;当序列化在 1997 年被添加到 Java 时，它被认为有点风险的。该方法已经在一种研究语言（Modula-3）中尝试过，但在生产中的语言中从未用过。虽然程序猿承诺在分布式对象上付出点努力得到的成果是很有吸引力的，代价是构造函数是不可见的而且它的 API 和实现之间的界限很模糊，在正确性、性能、安全性和维护方面可能存在问题。支持者认为这些好处【前面的成果】超过了风险，但历史已经证明并不是这样的。

&emsp;&emsp;本书前几版中描述的安全问题与某些人担心的一样严重。2000 年代早期讨论的小漏洞在接下来的十年被转化为严重的漏洞并被利用了，其中包括对旧金山都市交通局市政铁路（SFMTA Muni）的勒索软件攻击，该铁路在 2016 年 11 月关闭整个收费系统两天\[Gallagher16\]。

&emsp;&emsp;序列化的一个基本问题是它的*攻击面（attack surface）*太大而无法保护并且不断增长：通过在 ObjectInputStream 上调用 readObject 方法来反序列化对象数据图（object graphs）。这个方法本质上是一个神奇的构造函数，只要类型实现了 Serializable 接口，就可以在类路径上实例化几乎任何类型的对象。在反序列化字节流的过程中，此方法可以在这些类型中的任何一个类型执行代码，因此这些类的代码都是受攻击的一部分。

&emsp;&emsp;攻击的方向包括 Java 平台库中的类，第三方库（如 Apache Commons Collections）和应用程序本身。即使您遵守所有相关的最佳实践并成功编写无法攻击的可序列化类，您的应用程序仍可能容易受到攻击。引用 CERT 协调中心技术经理 Robert Seacord 的话：

> Java 反序列化是一个明显且存在的危险，因为它直接被应用程序广泛使用，并间接地由 Java 子系统（如 RMI（远程方法调用），JMX（Java 管理扩展）和 JMS（Java 消息系统））广泛使用。不受信任的流的反序列化可能导致远程代码被执行（RCE），拒绝服务（DoS）以及一系列其他漏洞被利用。应用程序即使没有做错也容易受到这些攻击。\[Seacord17\]。

&emsp;&emsp;攻击者和安全研究人员研究 Java 库和常用第三方库中的可序列化类型，查找在反序列化期间调用的执行方法潜在的危险活动。这种方法称为*小工具（gadgets）*。可以一起使用多个小工具来形成*小工具链（gadget chain）*。有时会发现在一个足够强大的小工具链中，只要有机会提交精心设计的字节流进行反序列化，就允许攻击者在底层硬件上执行任意本机代码（native code）。这正是 SFMTA Muni 攻击中发生的事情。这次袭击不是单独的。还有其他的，还会有更多。

&emsp;&emsp;在不使用任何小工具的情况下，你可以轻松地通过反序列化一个需要很长的反序列化时间的短流来发起拒绝服务（denial-of-service）攻击，这种流被称为*反序列化炸弹(deserialization bombs )*\[Svoboda16\]。这是 Wouter Coekaerts 的一个例子，它只使用哈希集和字符串\[Coekaerts15\]：

```java
// Deserialization bomb - deserializing this stream takes forever
static byte[] bomb() {
    Set<Object> root = new HashSet<>();
    Set<Object> s1 = root;
    Set<Object> s2 = new HashSet<>();
    for (int i = 0; i < 100; i++) {
        Set<Object> t1 = new HashSet<>();
        Set<Object> t2 = new HashSet<>();
        t1.add("foo"); // Make t1 unequal to t2
        s1.add(t1); s1.add(t2);
        s2.add(t1); s2.add(t2);
        s1 = t1;
        s2 = t2;
    }
    return serialize(root); // Method omitted for brevity
}
```

&emsp;&emsp;对象数据图由 201 个 HashSet 实例组成，每个实例包含 3 个或更少的对象引用。整个流的长度为 5,744 字节，但是远在你将其反序列化之前就会烧掉太阳【CPU】。问题在于反序列化 HashSet 实例需要计算其元素的哈希码。哈希集合的根的 2 个元素本身是包含 2 个哈希集元素的哈希集，每个哈希集元素包含 2 个哈希集元素，依此类推，深度为 100 个级别。

&emsp;&emsp;那么你能做些什么来抵御这些问题呢？每当您反序列化您不信任的字节流时，您就会打开攻击。**避免序列化漏洞被利用的最佳方法是永远不要反序列化任何东西** 。用 1983 年电影“战争游戏”中名为约书亚的电脑的话来说，“唯一的胜利之举就是不玩。”**在您编写的任何新系统中都没有理由使用 Java 序列化** 。还有其他在对象和字节序列之间进行转换的机制，可以避免 Java 序列化的许多危险，同时提供许多优势，例如跨平台支持，高性能，大型工具生态系统以及广泛的专业知识社区。在本书中，我们将这些机制称为*跨平台结构化数据表示（ cross-platform structured-data representations）*。虽然其他人有时将它们称为序列化系统，但本书避免了这种用法，以防止与 Java 序列化混淆。

&emsp;&emsp;这些【机制】表面特征的共同之处在于它们比 Java 序列化简单得多。它们不支持任意对象数据图的自动序列化和反序列化。相反，它们支持一组由属性-值（attribute-value）组成的简单结构化数据对象。仅支持少数基本数据类型和数组数据类型。这种简单的抽象足以构建极其强大的分布式系统，并且足够简单，可以避免从一开始就困扰 Java 序列化的严重问题。

&emsp;&emsp;领先的跨平台结构化数据表示是 JSON \[JSON\]和 Protocol Buffers，也称为 protobuf \[Protobuf\]。JSON 由 Douglas Crockford 设计用于浏览器-服务器通信，并且 Protocol Buffers 由 Google 设计用于在其服务器之间存储和交换结构化数据。即使这些表示有时被称为*中立语言（language-neutral）*，JSON 最初是为 JavaScript 开发的，而 protobuf 是为 C++开发的; 这两种的表现方式都保留了他们起源的痕迹。

&emsp;&emsp;JSON 和 protobuf 之间最显着的区别是 JSON 是基于文本的，人类可读的，而 protobuf 是二元的，效率更高; 并且 JSON 完全是数据表示，而 protobuf 提供*模式（schemas）*（类型）来记录和执行适当的用法。尽管 protobuf 比 JSON 更有效，但 JSON 对于基于文本的表示非常有效。虽然 protobuf 是二进制表示，但它确实提供了一种代替【二进制的】文本表示，它的用途是用于人类需要【数据具有】可读性的时候（pbtxt）。

&emsp;&emsp;如果您无法完全避免 Java 序列化，可能是因为你需要它在遗留系统的上下文中工作，那么您的下一个最佳选择是**永远不会反序列化不受信任的数据** 。特别是，您永远不应接受来自不受信任来源的 RMI 流量。Java 的官方安全编码指南说“不受信任数据的反序列化本质上是危险的，应该避免【反序列化不受信任的数据】。”这句话设置为大，粗体，斜体，红色类型，它是整个文档中唯一获得此处理的文本\[Java-secure\]。

&emsp;&emsp;如果您无法避免序列化，并且您不确定要反序列化的数据的安全性，请使用 Java 9 中添加的对象反序列化过滤并移植到早期版本（java.io.ObjectInputFilter）。此工具允许您指定一个过滤器，这个过滤器应用在反序列化之前的数据流【也就是要过滤反序列化之前的数据流】。它以类粒度运行，允许您接受或拒绝某些类。默认接受某些类并拒绝具有潜在危险的类的列表称为*黑名单（blacklisting）*；默认情况下拒绝某些类并接受假定安全的类的列表称为*白名单（whitelisting）*。**白名单优先于黑名单** ，因为黑名单只能保护你免受已知的威胁。使用白名单优于使用黑名单，因为黑名单只能保护您免受已知威胁。名为 Serial Whitelist Application Trainer（SWAT）的工具可用于为您的应用程序\[Schneider16\]自动准备白名单。过滤工具还可以保护您免受过多的内存使用和过深的对象数据图，但它不会保护您免受如上所示的序列化炸弹的攻击。

&emsp;&emsp;不幸的是，序列化在 Java 生态系统中仍然普遍存在。如果您要维护基于 Java 序列化的系统，请认真考虑迁移到跨平台的结构化数据表示，即使这可能是一项耗时的工作。实际上，您可能仍然发现自己必须编写或维护可序列化的类。编写一个正确，安全，高效的可序列化类需要非常小心。本章的其余部分提供了有关何时以及如何执行此操作的建议。

&emsp;&emsp;总之，序列化是危险的，应该避免【序列化】。如果您从头开始设计系统，请使用跨平台的结构化数据表示，例如 JSON 或 protobuf。不要反序列化不受信任的数据。如果必须这样做，请使用对象反序列化过滤，但请注意，这不能保证阻止所有的攻击。避免编写可序列化的类。如果你必须这样做，请谨慎行事。

## 谨慎地实现 Serializable 接口

&emsp;&emsp;要想使一个类的实例可被序列化，非常简单，只要在它的声明中加入“implemants Serializable”字样即可。正因为太容易了，所以普遍存在这样一种误解，认为程序猿可以毫不费力就可以实现序列化。实际情形要复杂得多。虽然使一个类可序列化的直接成本可以忽略不计，但长期的成本通常是很高的。

&emsp;&emsp;**实现 Serializable 接口而付出的最大代价是，一旦一个类被发布，就大大降低了“改变这个类的实现”的灵活性** 。当一个类实现了 Serializable 接口，它的字节流编码（或者说*序列化形式（serialized form）*）就变成了它的导出的 API 的一部分。一旦这个类被广泛使用，往往必须永远支持这种序列化形式，就好像你必须要支持导出的 API 的所有其他部分一样。如果你不努力设计一种*自定义的序列化形式（custom serialized form）*，而仅仅接受了默认的序列化形式，这种序列化形式将永远地束缚在该类最初的内部表示法上。换句话说，如果你接受了默认的序列化形式，这个类中私有的和包级私有的实例域都将变成导出的 API 的一部分，这不符合“将域的访问权限限制到最低”的实践准则（第 15 项），因此，将它【除了 public 以外的权限修饰符】作为信息隐藏工具，它就失去了有效性。

&emsp;&emsp;如果你接受了默认的序列化形式，并且以后又要改变这个类的内部表示，结果可能导致序列化形式的不兼容。客户端程序企图用这个类的旧版本来序列化一个类，然后用新版本进行反序列化（反之亦然），结果将导致程序失败。在改变内部表示法的同时仍然维持原来的序列化形式（使用 ObjectOutputStream.putFields 和 ObjectInputStream.readFields），这也是可能的，但是做起来比较困难，并且会在源代码中留下一些明显的隐患。如果你选择序列化一个类，你应该仔细地设计一种高质量的序列化形式，并且在很长时间内都愿意使用这种形式（第 87、90 项）。这样做会增加开发最初的成本，但这是值得的。即使是精心设计的序列化形式也会限制一个类的演变；一个设计不良的序列化形式可能会这个类无法演变（an ill-designed serialized form can be crippling）。

&emsp;&emsp;序列化会使类的演变受到限制，这种限制的一个例子与*流的唯一标识符（stream unique identifier）*有关，通常它也被称为*序列版本 UID（serial version UID）*。每个可序列化的类都有一个唯一标识号与它相关联。如果通过声明一个名为 serialVersionUID 的静态 final 的 long 域来指定此数字，系统则会在运行时通过将加密哈希函数（SHA-1）应用于类的结构来自动生成它。这个自动生成的值受类的名称、它实现的接口以及大多数成员（包括编译器生成的合成成员）的影响。如果你更改了以上的任何内容，比如，增加一个便捷方法，生成的序列版本 UID 就会发生变化。如果没有声明序列版本 UID，兼容性将会遭到破坏，从而导致运行时出现 InvalidClassException 异常。

&emsp;&emsp;**实现 Serializable 的第二个代价是，它增加了出现 BUG 和安全漏洞的可能性** 。通常情况下，对象是利用构造器来创建的；序列化机制是一种语言之外的对象创建机制（extralinguistic mechanism）。无论你是接受了默认的行为，还是覆盖了默认的行为，反序列化机制（deserialization）都是一个“隐藏的构造器”，具备与其他构造器相同的特点。因为反序列化机制中没有显式的构造器，所以你会很容易忘记确保以下这一点：反序列化过程必须也要保证所有“由真正的构造器建立起来的约束关系”，并且不允许攻击者访问正在构造过程中的对象的内部信息。依靠默认的反序列化机制，很容易使对象的约束关系遭到破坏，以及遭受到非法访问（第 88 项）。

&emsp;&emsp;**实现 Serializable 的第三个代价是，随着类发行新的版本，测试相关的负担也增加了** 。当一个可序列化的类被修订的时候，很重要的一点是，要检查是否可以“在新版本中序列化一个实例，然后在旧版本中反序列化”，反之亦然。因此，测试所需的工作量与“可序列化的类的数量和可能很大的发行版号”的乘积成正比。你必须确保“序列化-反序列化”过程成功，并且它产生的对象真的是原始对象的复制品。如果在最初编写一个类的时候，就精心设计了自定义的序列化形式，测试的需求就可以有所降低。

&emsp;&emsp;**实现 Serializable 接口并不是一个很轻松就可以做出的决定** 。如果一个类将要加入到某个框架中，并且该框架依赖于序列化来实现对象传输或者持久化，那么这一点至关重要。此外，它极大地简化了将类用作另一个必须实现 Serializable 的类的组件。但是，实现 Serializable 会产生许多开销。每次设计类的时候，都要权衡一下成本和收益。根据以往的经验，比如 BigInteger 和 Instant 这样的值类型的类实现了 Serializable，而且集合也这么做了。代表活动实体的类，比如线程池（thread pool），应该很少实现 Serializable。

&emsp;&emsp;**为了继承而设计的类（第 19 项）应该很少实现 Serializable 接口，接口也很少继承 Serializable 接口** 。违反此规则会给扩展类或实现接口的任何人带来沉重的负担。有时候违反这条规则是合适的。例如，如果一个类或者接口存在的主要是为了参与到某个框架中，该框架要求所有的参与者都必须实现 Serializable 接口，那么，对于这个类或者接口来说，实现或者扩展 Serializable 接口就是非常有意义的。

&emsp;&emsp;为了继承而设计的类中，实现了 Serializable 接口的包括 Throwable 和 Component。Throwable 实现了 Serializable 接口，所以 RMI 可以将异常从服务器发送到客户端。Component 实现了 Serializable 接口，因此 GUI 可以被发送、保存和恢复，但是即使在今天的 Swing 和 AWT 中，这个工具很少在实践中使用。

&emsp;&emsp;如果实现具有可序列化和可扩展的实例字段的类，则需要注意这几个风险。如果实例字段值上存在任何约束条件，则防止子类覆盖 finalize 方法至关重要，该类可以通过重写 finalize 并将其声明为 final 来完成。否则，该类将容易受到*终结者攻击（finalizer attacks）*（第 8 项）。最后，如果类的实例字段初始化为其默认值（整数类型为零，布尔值为 false，对象引用类型为 null），则会违反约束条件，必须为此添加 readObjectNoData 方法：

```java
// readObjectNoData for stateful extendable serializable classes
private void readObjectNoData() throws InvalidObjectException {
    throw new InvalidObjectException("Stream data required");
}
```

&emsp;&emsp;在 Java 4 中就添加了此方法，以涵盖涉及向现有可序列化类\[Serialization，3.5\]添加可序列化超类的极端情况。

&emsp;&emsp;关于不实现 Serializable 的决定有一点需要注意。如果为继承而设计的类不可序列化，则可能需要额外的努力才能编写可序列化的子类。这种类的正常反序列化要求超类具有可访问的无参数构造函数\[Serialization，1.10\]。如果您不提供这样的构造函数，则强制子类使用序列化代理模式（第 90 项）。

&emsp;&emsp;**内部类（第 24 项）不应该实现 Serializable 接口** 。它们使用编译器产生的*合成域（synthetic field）*来保存指向*外围实例（enclosing instabce）*的引用，以及保存来自外围作用域的局部变量的值。“这些域如何对应到类定义中”并没有明确的规定，就好像没有指定匿名类和局部类的名称一样。因此，内部类的默认序列化形式是定义不清楚的。然而，\*静态成员类（static member class）却可以实现 Serializable 接口。

&emsp;&emsp;总而言之，实现 Serializable 接口只是看起来很容易。除非只在受保护的环境中使用类，其中各个版本之间永远不必进行互操作，并且服务器永远不会暴露给不受信任的数据，否则实现 Serializable 接口是一个很严谨的承诺，应该认真对待。如果一个类允许继承，则需要格外小心。

## 考虑使用自定义的序列化形式

&emsp;&emsp;当你在时间紧迫的情况下设计一个类时，一般合理的做法是将精力集中在设计最佳的 API 上。有时候，这意味着要发行一个“用完后即丢弃”的实现，因为你知道以后会在新版本中将它替换掉。正常情况下，这不成问题，但是，如果这个类实现了 Serializable 接口，并且使用了默认的序列化形式，你就无法彻底摆脱那个应该丢弃的实现了。它将永远牵制住这个类的序列化形式。这不只是一个纯理论的问题，在 Java 平台类库中已经有几个类出现了这样的问题，比如 BigInteger。

&emsp;&emsp;**如果没有先认真考虑默认的序列化形式是否合适，就不要贸然接受** 。接受默认的序列化形式前应该有意识地从灵活性、性能和正确性多个角度来考察这种编码的合理性。一般来讲，只有当你自定义序列化形式与默认的序列化形式基本相同时，才能接受默认的序列化形式。

&emsp;&emsp;考虑以一个对象为根的对象图，相对于它的*物理（physical）*表示法而言，该对象的默认序列化形式是一种比较有效的编码形式。换句话说，默认的序列化形式描述了该对象内部所包含的数据，以及每一个可以从这个对象到达的其他对象的内部数据。它也描述了所有这些对象被连接起来后的拓扑结构。对于一个对象而言，理想的序列化形式应该只包含该对象所表示的*逻辑（logical）*数据，而逻辑数据与物理表示法应该是各自独立的。

&emsp;&emsp;**如果一个对象的物理表示法等同于它的逻辑内容，可能就适合于使用默认的序列化形式** 。例如，对于下面这些仅仅表示人名的类，默认的序列化形式就是合理的：

```java
// Good candidate for default serialized form
public class Name implements Serializable {
    /**
    * Last name. Must be non-null.
    * @serial
    */
    private final String lastName;
    /**
    * First name. Must be non-null.
    * @serial
    */
    private final String firstName;
    /**
    * Middle name, or null if there is none.
    * @serial
    */
    private final String middleName;
    ... // Remainder omitted
}
```

&emsp;&emsp;从逻辑的角度而言，一个名字包含三个字符串，分别代表姓、名和中间名。Name 中的实例域精确地反映了它的逻辑内容。

&emsp;&emsp;**即使你确定了默认的序列化形式是合适的，通常还必须提供一个 readObject 方法来保证约束关系和安全性** 。对于这个 Name 类而言，readObject 方法必须确保 lastName 和 firstName 是非 null 的。第 88 项和第 90 项将详细地讨论这个问题。

&emsp;&emsp;注意，虽然 lastName、firstName 和 middleName 域是私有的，但是它们仍然有相应的注释文档。这是因为，这些私有域定义了一个公有 API，即这个类的序列化形式，并且该公有的 API 必须建立文档。@serial 标签告诉 Javadoc 工具，把这些文档信息放在有关序列化形式的特殊文档页中。

&emsp;&emsp;下面的类与 Name 不同，它是另一个极端，该类表示了一个字符串列表（此刻我们暂时忽略关于“最好使用标准类库中 List 实现”的建议）：

```java
// Awful candidate for default serialized form
public final class StringList implements Serializable {
    private int size = 0;
    private Entry head = null;
    private static class Entry implements Serializable {
        String data;
        Entry next;
        Entry previous;
    }
    ... // Remainder omitted
}
```

&emsp;&emsp;从逻辑意义上讲，这个类表示了一个字符串序列。但是从物理意义上将，它把该序列表示成一个双向链表。如果你接受了默认的序列化形式，该序列化形式将不遗余力地镜像出（mirror）链表中的所有项，以及这些项之间的所有双向链接。

&emsp;&emsp;**当一个对象的物理表示法与它的逻辑数据内容有实质性的区别时，使用默认序列化形式会有以下 4 个缺点** ：

- **它使这个类导出的 API 永远地束缚在该类的内部表示法上** 。在上面的例子中，私有的 StringList.Entry 类变成了公有 API 的一部分。如果在将来的版本中，内部表示法发生了变化，StringList 类仍将需要接受链表形式的输入，并产生链表形式的输出。这个类永远也摆脱不了维护链表需要的代码，即使它不再使用链表项作为内部数据结构。

- **它会消耗过多的空间** 。在上面的例子中，序列化形式既表示了链表中的每个项，也表示了所有的连接关系，这是不必要的。这些链表项以及连接只不过是实现细节，不值得记录在序列化形式中。因为这样的序列化形式过于庞大，所以，把它写到磁盘中，或者在网络上发送都将非常慢。

- **它会消耗过多的时间** 。序列化逻辑并不了解对象图的拓扑关系，所以它必须要遍历一个图，这个过程的代价是非常高的，在上面的例子中，沿着 next 引用进行遍历是非常简单的。

- **它会引起栈溢出** 。默认的序列化过程要对对象图进行递归遍历，即使对于中等大小的对象图，也可能导致堆栈溢出。在我的机器上，如果 StringList 实例包含 1000~1800 个元素，对它进行序列化就会导致堆栈溢出。令人惊讶的是，序列化导致堆栈溢出的最小列表的大小在每次运行的时候都不一样（在我的机器上）。出现该问题的最小列表的大小可能取决于平台的实现和命令行的参数；某些【虚拟机的】实现可能根本没有这个问题。

&emsp;&emsp;对于 StringList 类，合理的序列化形式可以非常简单，只需先包含链表中字符串的数目，然后紧跟着这些字符串即可。这样就构成了 StringList 所表示的逻辑数据，与它的物理表示细节脱离。下面是 StringList 的一个修订版本，它包含 writeObject 和 readObject 方法，用来实现这样的序列化形式。顺便提醒一下，transient 修饰符表明这个实例域将从一个类的默认序列化形式中省略掉：

```java
// StringList with a reasonable custom serialized form
public final class StringList implements Serializable {
    private transient int size = 0;
    private transient Entry head = null;
    // No longer Serializable!
    private static class Entry {
        String data;
        Entry next;
        Entry previous;
    }
    // Appends the specified string to the list
    public final void add(String s) { ... }
    /**
    * Serialize this {@code StringList} instance.
    *
    * @serialData The size of the list (the number of strings
    * it contains) is emitted ({@code int}), followed by all of
    * its elements (each a {@code String}), in the proper
    * sequence.
    */
    private void writeObject(ObjectOutputStream s) throws IOException {
        s.defaultWriteObject();
        s.writeInt(size);
        // Write out all elements in the proper order.
        for (Entry e = head; e != null; e = e.next)
            s.writeObject(e.data);
    }
    private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException {
        s.defaultReadObject();
        int numElements = s.readInt();
        // Read in all elements and insert them in list
        for (int i = 0; i < numElements; i++)
            add((String) s.readObject());
    }
    ... // Remainder omitted
}
```

&emsp;&emsp;writeObject 方法要做的第一件事是调用 defaultWriteObject，readObject 方法要做的第一件事是调用 defaultReadObject，即使 StringList 的所有域都是瞬时的（transient）。你可能听到有一种说法是：如果类的所有实例域都是瞬时的，您可以省去调用 defaultWriteObject 和 defaultReadObject，但序列化规范要求您无论如何都要调用它们。这些调用的存在使得可以在以后的版本中添加非瞬时的实例域，同时保持向后和向前的兼容性。如果某一个实例将在未来版本中被序列化，然后在前一个版本中被反序列化，那么，后增加的域将被忽略掉。如果旧版本中的 readObject 方法没有调用 defaultReadObject，反序列化过程将失败，引发 StreamCorruptedException 异常。

&emsp;&emsp;注意，尽管 writeObject 方法是私有的，它也有文档注释。这与 Name 类中私有域的文档注释是同样的道理。该私有方法定义了一个共有的 API，即序列化形式，并且这个公有的 API 应该建立文档。如同域的@serial 标签一样，方法的@serialData 标签也告知 Javadoc 工具，要把该文档信息放在有关序列化形式的文档页上。

&emsp;&emsp;套用以前对性能的讨论形式，如果平均字符串长度为 10 个字符，StringList 修订版本的序列化形式就只占用原序列化形式一半的空间。在我的机器上，对于同样是 10 个字符串长度的情况下，StringList 修订版的序列化速度比原版本的快 2 倍。最终，修订版中不存在栈溢出的问题，因此，对于可被序列化的 StringList 的大小也没有实际的上限。

&emsp;&emsp;虽然对于 StringList 来说【使用】默认的序列化形式并不好，但是【对于】有些类可能会更糟糕。对于 StringList，默认的序列化形式不够灵活，并且执行效果不佳，但是序列化和反序列化 StringList 实例会产生对原始对象的拷贝是可靠的，它的约束关系没有被破坏，从这个意义上讲，这个序列化形式是正确的。但是，如果对象的约束关系要依赖于特定于实现的细节，对于它们来说，情况就不是这样的了。

&emsp;&emsp;例如，考虑散列表的情形。它的物理表示法是一系列包含“键-值（key-value）项的散列桶。一个项属于哪一个桶，这是该键关于散列码的一个函数，一般情况下，不同的实现不保证会有相同的效果。实际上，即使在相同的实现中，也无法保证，每次运行【产生的结果】都是一样的。因此，对于散列表而言，接受默认的序列化形式将会产生一个严重的 BUG。序列化和反序列哈希表产生的对象，其约束关系会遭到严重的破坏。

&emsp;&emsp;无论你是否使用默认的序列化形式，当 defaulWriteObject 方法被调用的时候，每一个未被标记为 transient 的实例域都会被序列化。因此，每一个可以被标记为 transient 的实例都应该做上这样的标记。这包括那些冗余的域，即这些域的值可以根据其他“基本数据域”计算而得到，比如缓存起来的散列值。它也包括那些“其值依赖于 JVM 的某一次运行”的域，比如一个 long 域代表了一个指向本地数据结构的指针。**在决定将一个域做成非 transient 的之前，请一定要确信它的值将是该对象逻辑状态的一部分** 。如果你正在使用一种自定义的序列化形式，那么，大多数实例域，或者所有的实例域都应该被标记为 transient，就像上面例子中的 StringList 那样。

&emsp;&emsp;如果你正在使用默认的序列化形式，并且把一个或者多个域标记为 transient，则要记住，当一个实例域被反序列化的时候，这些域将被初始化为它们的默认值（default value）：对于对象引用域，默认值为 null；对于数值基本域，默认值为 0；对于 boolean 域，默认值为 false\[JLS, 4.12.5\]。如果这些值不能被任何 transient 域所接受，你就必须提供一个 readObject 方法，它首先调用 defaultReadObject，然后把这些 transient 域恢复为可接受的值（第 88 项）。另一种方法是，这些域可以在第一次使用时进行延迟初始化（第 83 项）。

&emsp;&emsp;无论你是否使用默认的序列化形式，**如果在读取整个对象状态的其他方法上强制【进行】同步，则也必须在对象序列化【方法】上强制【使用】同步** 。因此，如果你有一个线程安全的对象（第 82 项），它通过同步每个方法实现了它的线程安全，并且你选择使用默认的序列化形式，就要使用下列的 writeObject 方法：

```java
// writeObject for synchronized class with default serialized form
private synchronized void writeObject(ObjectOutputStream s) throws IOException {
    s.defaultWriteObject();
}
```

&emsp;&emsp;如果你把同步放在 writeObject 方法中，就必须确保它遵守与其他动作相同的锁排列（lock-ordering）约束条件，否则就有遭遇资源排列（resource-ordering）死锁的危险 \[Goetz06, 10.1.5\]。

&emsp;&emsp;**不管你选择了哪种序列化方式，都要为自己编写的每个可序列化的类声明一个显示的序列版本 UID（serial version UID）** 。这样可以避免序列版本 UID 成为潜在的不兼容根源（第 86 项）。而且这样做在性能上也会带来一点好处。如果没有显示地提供序列版本 UID，就需要在运行时通过一个高开销的计算过程产生一个序列版本 UID。

&emsp;&emsp;要声明一个序列版本 UID 非常简单，只要在你的类中增加下面一行：

> private static final long serialVersionUID = _randomLongValue_;

&emsp;&emsp;如果你编写一个新的类，为 randomLongValue 选择什么值并不重要。通过在该类上运行 serialver 工具，你就可以得到一个这样的值，但是，如果你凭空编造一个数值，那也是可以的。如果你想修改一个没有序列版本 UID 的现有的类，并希望新的版本能够接受现有的序列化实例，就必须使用那个自动为旧版本生成的值。如通过在旧版本的类上运行 serialver 工具，可以得到这个数值——存在序列化实例的那个数值【有一些实例是通过那个值序列化的】。

&emsp;&emsp;如果你想为一个类生成一个新的版本，这个类与现有的类*不兼容（incompatible）*，那么你只需要修改序列版本 UID 声明中的值即可。这会导致，前一个版本的实例经过序列化之后，再做反序列化时会抛出 InvalidClassException 异常而失败。**除非您要破坏与现有类的所有序列化实例的兼容性，否则请勿更改序列版本 UID** 。

&emsp;&emsp;总而言之，当你决定要将一个类做成可序列化的时候（第 86 项），请仔细考虑应该采用什么样的序列化形式。之后当默认的序列化形式能够合理地描述对象的逻辑状态时，才能使用默认的序列化形式；否则就要设计一个自定义的序列化形式，通过它合理地描述对象的状态。你应该分配足够多的时间来设计类的序列化方式，就好像分配足够多的实时间来设计它的导出方法一样（第 51 项）。正如你无法在将来的版本中去掉导出的方法一样，你也不能去掉序列化形式中的域；它们必须被永久地保留下去，以确保序列化兼容性（serialization compalibility）。选择错误的序列化形式对于一个类的复杂性和性能都会有永久的负面影响。

## leetcode
### 单词搜索
回溯算法 + dfs

```
class Solution {
    public boolean exist(char[][] board, String word) {
        for (int i = 0; i < board.length; ++i) {
            for (int j = 0; j < board[i].length; ++j) {
                if (board[i][j] == word.charAt(0)) {
                    if (dfs(board, word, i, j, 0)) return true;
                }
            }
        }
        return false;
    }
    public boolean dfs(char[][] board, String word, int i, int j, int k) {
        if (k == word.length()) {
            return true;
        }
        if (i < 0 || j < 0 || i >= board.length || j >= board[i].length) {
            return false;
        }
        
        if (word.charAt(k) != board[i][j]) {
            return false;
        }
        char t = board[i][j];
        board[i][j] = '0';
        boolean res = dfs(board, word, i + 1, j, k + 1) || 
        dfs(board, word, i - 1, j, k + 1) || 
        dfs(board, word, i, j + 1, k + 1) || 
        dfs(board, word, i, j - 1, k + 1);
        board[i][j] = t;
        return res;
    }
}
```

### 构建乘积数组
```
import java.util.ArrayList;
public class Solution {
    public int[] multiply(int[] A) {
        int[] B = new int [A.length];
        int temp = 0;
        for(int i = 0; i < A.length; i++){
            temp = A[i];
            A[i] = 1;
            B[i] = 1;
            for(int j = 0; j < A.length; j++){
                B[i] *= A[j]; 
            }
            A[i] = temp;
        }
        return B;
    }
}
```