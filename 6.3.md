# 6.3工作日志
## 文件锁

在多数unix系统中，当多个进程/线程同时编辑一个文件时，该文件的最后状态取决于最后一个写该文件的进程。

对于有些应用程序，如数据库，各个进程需要保证它正在单独地写一个文件。这时就要用到文件锁。

文件锁（也叫记录锁）的作用是，当一个进程读写文件的某部分时，其他进程就无法修改同一文件区域。

能够实现文件锁的函数主要有2个：flock和fcntl。

flock函数只能对整个文件加锁，不能对文件的一部分加锁。

lockf是在fcntl基础上构造的函数，它提供了一个简化的接口。它们允许对文件中任意字节区域加锁，短至一个字节，长至整个文件。

* 锁类型：共享读锁F_RDLCK，独占性写锁F_WRLCK，解锁F_UNLCK
* 加锁或解锁区域的起始字节偏移量（l_start, l_whence）
* 区域字节长度（L_len）
* 进程的id持有的锁能阻塞当前进程，仅由F_GETLK返回
* 锁可以在文件尾处开始或者越过尾端开始，但是不能在文件起始位置之前开始
* 若l_len=0, 表示锁的范围可以扩大到最大可能偏移量，这意味着不管向文件中追加多少数据，它们都可以处于锁的范围内，而且起始位置可以任意
* 设置l_start和l_whence指向文件的起始位置，并且指定l_len=0，以实现对整个文件加锁（一般l_start=0, l_whence=SEEK_SET）

## 锁
在多用户都用事务同时访问同一个数据资源的情况下，会造成更新丢失、不可重复读、脏读、幻读，所以为解决这些问题有了不同锁

提到锁可能就会想起乐观锁、悲观锁、行锁、表锁等等概念，其实他们不是并列的关系。
乐观锁和悲观锁是一种加锁的思想；行级锁和表级锁是锁的粒度，表示加锁的范围；而共享锁和排他锁才是真正的锁，用来锁住数据。下面我们分别讨论一下它们。

#### 1.1乐观锁和悲观锁


<table>
	<tr>
		<td>锁名</td>
		<td>机制</td>
		<td>实现原理</td>
		<td>优点</td>
		<td>缺点</td>
		<td>适用场景</td>
	</tr>
	<tr>
		<td>乐观锁</td>
		<td>整个处理过程不加锁，直到处理完准备提交时，才通过版本号检查数据是否提交</td>
		<td>大多是基于数据版本（ Version ）记录机制实现，即为每条数据增加一个记录版本号的字段，读取数据时，将版本号一同读出，更新时对此版本号加一，此时若提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为数据已经被其它事务修改过，需要回滚和重试</td>
		<td>避免了加锁的开销和死锁的出现，提高了系统的并发性能</td>
		<td>来自外部系统的更新操作不受控制	</td>
		<td>适用于写操作比较少，数据冲突较少的场景
</td>
	</tr>

	<tr>
		<td>悲观锁</td>
		<td>数据处理开始时就对数据加锁，直到处理完成才释放锁</td>
		<td>需要利用数据库本身提供的锁机制来实现，例如共享锁、排他锁	</td>
		<td>外部系统的更新操作也受控制，最大限度的为数据处理的安全性提供了保证</td>
		<td>加锁开销大，增加产生死锁的可能性，大大降低系统的并发性能</td>
		<td>适用于写操作比较多，数据冲突严重的场景
</td>
	</tr>
</table>

#### 1.2共享锁和排他锁

<table>
	<tr>
		<td>锁名</td>
		<td>机制</td>

	</tr>
	<tr>
		<td>共享锁</td>
		<td>
1. 当事务A对某资源加了共享锁后，其它事务也只能对该资源加共享锁
2. 若想加排他锁，需等待所有事务释放共享锁
3. 持有共享锁的事务，都可以读取该资源，但不能修改
		</td>

	</tr>

	<tr>
		<td>排他锁</td>
		<td>
		1.当事务A对某资源加了排他锁后，事务A可以读取和修改该资源
2.其它事务不能对该资源加任何锁，直到事务A释放排他锁</td>

	</tr>
</table>

**举个栗子**

前提:还是上面那个表，MySQL加共享锁是通过查询语句后加lock in share mode，就代表对某些资源加上共享锁了。

*1)首先A事务，加共享锁*

![\屏幕快照 2018-07-23 11.31.23.png][0.6296616949817813]


*2)B事务更新语句*

![\屏幕快照 2018-07-23 11.33.46.png][0.28302350457198044]

会发现卡住了一会，然后报错，这说明，上个事务没commit前，被锁住了，不能更新,所以我们加个共享锁试一下。

![\屏幕快照 2018-07-23 11.35.17.png][0.6218123387116514]

可以看到报错了，注意上面的共享锁机制只能读取资源，不能修改（这是因为MySQL中，update delete insert 语句会自动加个排他锁）。所以我们在B试下读取资源。

![\屏幕快照 2018-07-23 11.36.47.png][0.5429371639369425]

没问题！

*再举个排他锁的栗子*

前提:还是上面那个表，MySQL加共享锁是通过查询语句后加for update，就代表对某些资源加上排他锁了。

*1)还是首先对A事务操作，加排他锁*

![\屏幕快照 2018-07-23 11.40.08.png][0.5569636070495774]

*2)然后事务B分别不加锁查询，加排他锁查询，加共享锁查询*

![\屏幕快照 2018-07-23 11.44.00.png][0.9093625796814668]

然后可以发现加锁都会阻塞。


#### 1.3表级锁和行级锁

表级锁和行级锁是一种锁的粒度。一般来说，锁粒度越小，锁冲突就越少，系统的并发性能就更高，但同时数据库在管理锁方面的开销也越大，当管理锁的开销比数据存取的开销还要大时，反而可能会影响到系统的性能。 
在MySQL中，每个存储引擎都可以有自己的锁策略，例如MyISAM引擎仅支持表级锁，而InnoDB引擎除了支持表级锁外，也支持行级锁（默认）。行级锁可以最大程度地支持并发处理。



##### 1.3.1 InnoDB

*InnoDB与MyISAM的最大不同有两点：*

* 支持事务（TRANSACTION)
* 采用了行级锁。

行级锁和表级锁本来就有许多不同之处，另外，事务的引入也带来了一些新问题。

InnoDB行锁是通过索引上的索引项来实现的，这一点ＭySQL与Oracle不同，后者是通过在数据中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表锁**！
在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。

**间隙锁（Next-Key锁）**

当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制不是所谓的间隙锁（Next-Key锁）。
    举例来说，假如一个表中只有101条记录，其id的值分别是1,2,...,100,101，下面的SQL：
SELECT * FROM emp WHERE id > 100 FOR UPDATE
    是一个范围条件的检索，InnoDB不仅会对符合条件的id值为101的记录加锁，也会对id大于101（这些记录并不存在）的“间隙”加锁。
    InnoDB使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了id大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。
    很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。
    
**加表锁的情况**  

对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个另特殊事务中，也可以考虑使用表级锁。

* 事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。
* 事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。
当然，应用中这两种事务不能太多，否则，就应该考虑使用MyISAＭ表。
在InnoDB下 ，使用表锁要注意以下两点。
* 使用LOCK TALBES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。
* 在用LOCAK TABLES对InnoDB锁时要注意，要将AUTOCOMMIT设为0，否则ＭySQL不会给表加锁；事务结束前，不要用UNLOCAK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK产不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁，



##### 1.3.2 MyISAM

MyISAM引擎下，有两种模式，表共享锁（Table Read Lock）和表独占写锁（Table Write Lock）。

* 对MyISAM的读操作，不会阻塞其他用户对同一表请求，但会阻塞对同一表的写请求；
* 对MyISAM的写操作，则会阻塞其他用户对同一表的读和写操作；

MyISAM表的读操作和写操作之间，以及写操作之间是串行的。
当一个线程获得对一个表的写锁后，只有持有锁线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。
所以MyISAM表的读和写操作之间，以及写和写操作之间是串行的！（当一线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。）

MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要直接用LOCK TABLE命令给MyISAM表显式加锁。

**并发锁**

在一定条件下，MyISAM也支持查询和操作的并发进行。
MyISAM存储引擎有一个系统变量concurrent_insert，专门用以控制其并发插入的行为，其值分别可以为0、1或2。

* 当concurrent_insert设置为0时，不允许并发插入。
* 当concurrent_insert设置为1时，如果MyISAM允许在一个读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置。
* 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾插入记录，都允许在表尾并发插入记录。

可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入锁争用。例如，将concurrent_insert系统变量为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIONMIZE TABLE语句来整理空间碎片，收到因删除记录而产生的中间空洞。


#### redo log、undo log、 binlog
日志系统主要有redo log(重做日志)和binlog(归档日志)。redo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）。

redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。在实例和介质失败（media failure）时，redo log文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。

在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术，他的关键点是先写日志，再写磁盘。

有了redo log日志，那么在数据库进行异常重启的时候，可以根据redo log日志进行恢复，也就达到了crash-safe。

redo log日志的大小是固定的，即记录满了以后就从头循环写。
binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑，依靠binlog是没有crash-safe能力的



#####  一条更新语句执行的顺序:

update T set c=c+1 where ID=2;

执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。


undo log:保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读


##### 一个事务执行

* 写undo日志到log buffer；
* 执行事务，并写redo日志到log buffer；
* 如果innodb_flush_log_at_trx_commit=1，则将redo日志写到log file，并刷新落盘。
* 提交事务。

##### redo log和binlog区别
* redo log是属于innoDB层面，binlog属于MySQL Server层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。
* redo log是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑
* redo log是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。
* binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。



## leetcode
### 电话号码的字母组合
回溯，递归

```
class Solution {
    public List<String> letterCombinations(String digits) {
        List<String> combinations = new ArrayList<String>();
        if (digits.length() == 0) {
            return combinations;
        }
        Map<Character, String> phoneMap = new HashMap<Character, String>() {{
            put('2', "abc");
            put('3', "def");
            put('4', "ghi");
            put('5', "jkl");
            put('6', "mno");
            put('7', "pqrs");
            put('8', "tuv");
            put('9', "wxyz");
        }};
        backtrack(combinations, phoneMap, digits, 0, new StringBuffer());
        return combinations;
    }

    public void backtrack(List<String> combinations, Map<Character, String> phoneMap, String digits, int index, StringBuffer combination) {
        if (index == digits.length()) {//index为数字第n位。Index自增至.length()则停止下面的else模块递归
            combinations.add(combination.toString());//index增至数字串长度，加入集合
        } else {
            char digit = digits.charAt(index);//输入的数字串的第index位数字
            String letters = phoneMap.get(digit);//该数字对应map中的字母
            int lettersCount = letters.length();//字母个数
            for (int i = 0; i < lettersCount; i++) {//遍历该位数字对应的字母
                combination.append(letters.charAt(i));
                backtrack(combinations, phoneMap, digits, index + 1, combination);//ex: AD,AE,AF每次循环删除第二位的数
                combination.deleteCharAt(index);//ex: A的递归完，删除本位的A进行下次循环
            }
        }
    }
}
```

### 第一个只出现一次的字符
```
public class Solution {
    public int FirstNotRepeatingChar(String str) {
        //遍历时间复杂度为O(n^2),可开辟一块空间用来装每个元素出现的次数
        if(str == null || str.length() == 0){
            return -1;
        }
        //新建计数数组
        int[] count = new int[256];//数组大小应设多少？
        //遍历字符串记每个元素出现次数
        for(int i = 0;i < str.length();i++){
            count[str.charAt(i)]++;
        }
        for(int i = 0;i < str.length();i++){
            if(count[str.charAt(i)] == 1){
                return i;
            }
        }
        //若无则返回-1
        return -1;
    }
}
```