# 6.6学习日志
## SQL执行流程之物理优化

### 物理优化
物理优化就是通过计算代价的方式来对多种可能的方法进行筛选，优胜劣汰。
代价就是一个执行计划在执行过程中所带来的消耗。既然是数据库，数据都保存在磁盘上，那么就免不了读取磁盘带来的消耗，这种消耗可以称为 IO 代价。在 SQL 语句中需要执行各种表之间做逻辑运算，看到“运算”两个字就很容易想到 CPU，因为 CPU 是中央处理单元，所以执行计划还要考虑 CPU 代价。由于分布式计划（或者并行执行计划）对数据进行了切分，导致在执行计划之间需要传递数据，因此还需要考虑通信代价。

代价= IO代价+CPU代价+通信代价

那么问题来了，这些代价如何计算呢？当然可以采用最简单的“拍脑袋大法”，比如在路径选择的时候我们就喜欢记住这样的模糊的概念：通过建索引的方式可以提高查询速度。基于此，在打算提高查询性能的时候，一拍脑袋就在一个表上建上百个索引，美其名曰用空间换时间，除了更新和插入的速度慢一点，简直没毛病。

但优化器的代价模型不满足于这种含糊其辞式概念，需要做“精确”的计算，于是就需要如下几个方面的信息。

* 数据到底是什么情况？也就是说数据的分布情况，比如它占了多少个页面，有多少个元组，元组的宽度是多少，每一列里有没有 NULL 值，有没有那种重复度特别高的列（比如性别）等。
* 如何量化 IO 和 CPU 的消耗？我们都知道“距离 = 速度 × 时间”，数据分布就好比是速度，那么量化的 IO 和 CPU 消耗就好像是时间，数据分布和量化的 IO 和 CPU 消耗相乘，才能获得代价。
* 执行计划是如何执行的？假设我们知道读取一个页面需要的 IO 消耗是 1，一个表有 1000 个页面，此时执行计划选择了通过索引读取结果，很可能有一些页面就被跳过了，因此还需要知道执行计划是如何执行的才能计算代价。


#### 统计信息

PostgreSQL 数据库最早只支持单列的统计信息，也就是说我们对一个表执行 ANALYZE 之后，它会针对这个表的每一列建立一组统计信息，这组统计信息包括如下类型。

* 高频值（常见值），在一个列里出现最频繁的值，按照出现的频率进行排序，并且生成一个一一对应的频率数组，这样就能知道一个列中有哪些高频值，这些高频值的频率是多少。

* 直方图，PostgreSQL 数据库使用等频直方图来描述一个列中的数据的分布，高频值不会出现在直方图中，这就保证了数据的分布是相对平坦的。

* 相关系数，相关系数记录的是当前列未排序的数据分布和排序后的数据分布的相关性，这个值通常在索引扫描时用来估计代价。假设一个列未排序和排序之后的相关性是 0，也就是完全不相关，那么索引扫描的代价就会高一些。

* 数组高频值（常见值），用于数组类型或者一些其他类型，PostgreSQL 数据库提供了 ts_typanalyze 系统函数来负责生成这种类型的统计信息。

* 数组类型直方图，用于给数组类型生成直方图。PostgreSQL 数据库提供了 array_typanalyze 系统函数来负责生成这种类型的统计信息。

* 为 Range 类型生成一个基于长度的直方图统计信息，用户可以自定义 Range 类型，例如 CREATE TYPE floatrange AS RANGE (subtype = float8, subtype_diff = float8mi)，PostgreSQL 数据库提供了 range_typanalyze 系统函数负责生成这种类型的统计信息。

* 为 Range 类型生成一个基于边界的直方图，这种类型的直方图也通过 range_typanalyze 系统函数来进行统计；


PostgreSQL 除了支持单列的统计信息之外，还支持了多列的统计信息用来计算各个列之间的依赖度，它主要包括以下两种形式。

* 去重统计信息，和单列统计信息中的 stadistinct 是类似的，stadistinct 中记录的是单列中去掉 NULL 值和消重之后的数据量或者比例。STATS_EXT_NDISTINCT 类型的统计信息则记录的是基于多列的消重之后的数据量。

* 依赖统计信息，计算各个列之间的函数依赖度，通过函数依赖度计算各个列之间的依赖关系，从而得到准确的统计信息。

统计信息的生成是通过采样数据来生成的，也就是从一个表中抽样出来一部分数据作为样本，样本是否显著就决定了统计信息是否准确。PostgreSQL 使用了两阶段采样，第一个阶段是对页面进行采样。因为页面的数量是精确的，所以采用随机的方法采样就可以了。第二个阶段是从获得的采样页面中再次采样元组。由于元组的数量是不精确的，因而采用的是蓄水池算法进行采样。无论采用什么样的采样算法，总会有统计的偏差存在，通常我们可以通过调整 default_statistics_target 参数来设定样本的容量。

如果用户要给某一个表生成统计信息，可以使用 ANALYZE 语句对一个表进行统计分析，这样就能给这个表生成统计信息并且保存在 PG_STATISTIC 系统表中。



starelid/staattnum：对应的表的 OID（来自 PG_CLASS）和列的编号（来自 PG_ATTRIBUTES），其中 sno、sname、ssex 这 3 个属性的编号分别是 1、2、3。

stanullfrac：NULL 值率，表示一个属性（列）里 NULL 值所占的比例，如示例所示，STUDENT 表的sname 和 ssex 两个列中各有一个 NULL 值，因此它们 NULL 值率都是 1/7 = 0.142857。

stawidth：计算该属性（列）的平均宽度，STUDENT 表的第一个属性 sno 是 INT 类型。INT 类型是定长类型，它的宽度是 4；而 STUDENT 表的第二个属性 sname 是变长的类型，它的宽度是所有值的平均宽度。虽然 sname 的类型是 VARCHAR(10)，但是实际上我们插入的值全部长度都是 2，再加上 VARCHAR 类型的 Header 的 1 个字节的长度，可以获得它的平均宽度是 3。

stadistinct：计算该属性消重之后的数据的个数或比例，stadistinct 的取值有 3 种情况：
* = 0，代表未知或者未计算的情况
* > 0，代表消除重复值之后的个数，不常使用这种情况
* < 0，其绝对值是去重之后的属性个数占总个数的比例，通常使用这种情况

#### 选择率

通过统计信息，代价估算系统就可以了解一个表有多少行数据、用了多少个数据页面、某个值出现的频率等，然后根据这些信息计算出一个约束条件能过滤掉多少数据，这种约束条件过滤出的数据占总数据量的比例称为“选择率”。

选择率 = 筛选之后所剩的元组数量 / 筛选之前的元组数量

选择率与随机 IO 的关系
获得了统计信息之后，在代价估算的时候就可以利用这些统计信息进行计算，比如可以借用统计信息计算约束条件的选择率：
在选择率高的情况下查询路径选择了顺序扫描（SeqScan）的方式，在选择率低的情况下查询路径选择了索引扫描（IndexScan）。这是因为对于索引扫描而言，它产生了“随机读”，PostgreSQL 数据库中堆表的数据是无序的，而主键索引则以 B 树的方式进行存储。B 树的叶子结点是有序的，如果通过顺序扫描（SeqScan）的方式对 STUDENT 表进行遍历，则需要对每一个 STUDENT 表中的元组应用约束条件，筛选出符合约束条件的元组作为结果。如果通过索引扫描的方式，则可以借助 B 树索引的有序性，快速定位索引项的位置，每一个索引项都有一个堆元组的“地址”，这个“地址”指向了该索引项对应的 STUDENT 表中的元组。因为索引项是有序的，而 STUDENT 表中的元组是无序的，所以这时就产生了随机读。而在 PostgreSQL 数据库中对于顺序读和随机读定义了不同的代价。

SEQ_PAGE_COST  1.0       //顺序读的单页代价
RANDOM_PAGE_COST  4.0    //随机读的单页代价

如果选择率比较高，那么随机读的代价累计起来就很可观了。因此在选择率高的情况下会选择顺序扫描，而当选择率比较低时，顺序扫描仍然要把整个表的数据过滤一遍。索引扫描的单个随机读代价虽然高，但总量远远小于顺序读的数据量，因此顺序读的累计的代价就会超过索引扫描的代价，这时就会选择索引扫描作为执行路径。

如果选择率比较高，那么随机读的代价累计起来就很可观了。因此在选择率高的情况下会选择顺序扫描，而当选择率比较低时，顺序扫描仍然要把整个表的数据过滤一遍。索引扫描的单个随机读代价虽然高，但总量远远小于顺序读的数据量，因此顺序读的累计的代价就会超过索引扫描的代价，这时就会选择索引扫描作为执行路径。

PostgreSQL 数据库分别采用了动态规划方法和遗传算法来选择最优的执行计划。动态规划方法需要遍历全部的解空间（有优化），它一定能够获得最优解，因此是我们首选的方法。遗传算法则只能尝试从局部最优解向全局最优解不断逼近，但由于遗传代际的数量的限制，最终可能产生的是局部最优解。这种方法在表比较多的时候被采用，因为在表比较多的时候，动态规划的解空间快速地膨胀，可能会导致查询性能的下降，遗传算法的复杂度则可以限制在一定的范围内。

嵌套循环连接、哈希连接、归并连接

遗传算法：
物竞天择，适者生存，这是大自然的普遍规律。PostgreSQL 把这种普遍的方法借用到连接路径搜索中，一方面是借助了随机的威力，另一方面是借助了遗传的特点。

我们常说进行连接操作的表超过 12 个就可能会通过遗传算法来进行最优路径的筛选工作，但实际上这个值是受 GUC 参数 geqo_threshold 控制的，这个 GUC 参数的默认值是 12。

不过即使参与连接的表达到了 geqo_threshold 的要求，PostgreSQL 也不会轻易选择遗传算法，还需要通过另一个 GUC 参数 geqo 打开遗传算法。

#### 代价估计

整体代价 = IO 代价 + CPU 代价

IO 代价通常是和页面相关的代价，PostgreSQL 的数据是保存在页面里的，每个页面默认是 8k，所以 IO 代价通常和一个表所占的页面数量有关。CPU 代价是对元组进行处理的代价，一个页面上会保存多个元组，在拿到其中一个元组之后，要对这个元组进行表达式计算，这部分代价主要是 CPU 代价。下面分别计算 SeqScan 的IO 代价和 CPU 代价，最终获得 SeqScan 的整体代价：


```
IO 代价 = 55 个页面 * SEQ_PAGE_COST = 55
CPU 代价 = 10000 条元组 * CPU_TUPLE_COST = 100
整体代价 = IO 代价 + CPU 代价 = 155
```

我们把 SEQ_PAGE_COST 称为顺序 IO，把 RANDOM_PAGE_COST 称为随机 IO，“顺序IO”和“随机IO”是相对应的，从基准代价的定义可以看到这二者之间相差 4 倍，造成这种差距主要有如下两个原因。

* 目前的存储介质大部分仍然是机械硬盘，机械硬盘的磁头在获得数据库的时候需要付出寻道时间。如果要读写的是一串在磁盘上连续的数据，就可以节省寻道时间，提高 IO 性能；而如果随机读写磁盘上任意扇区的数据，那么会有大量的时间浪费在寻道上。
* 大部分磁盘本身带有缓存，这就形成了主存→磁盘缓存→磁盘的三级结构。在将磁盘内容加载到内存的时候，考虑到磁盘的 IO 性能，磁盘会进行数据的预读，把预读到的数据保存在磁盘的缓存中。也就是说如果用户只打算从磁盘读取 100 字节的数据，磁盘可能会连续读取磁盘中的 512 字节（不同的磁盘预读的数量可能不同），并将其保存到磁盘缓存。如果下一次是顺序读取 100 字节之后的内容，那么预读的 512 字节的数据就会发挥作用，性能会大大地增加。而如果读取的内容超出了 512 字节的范围，那么预读的数据就没有发挥作用，磁盘的 IO 性能就会下降。


## leetcode


### 矩形覆盖
```
public class Solution {
    public int rectCover(int target) {
        //递归
        if(target == 0 || target == 1|| target == 2) return target;
        return rectCover(target - 1)+rectCover(target - 2);
    }
}
```

### 数值的整数次方
```
public class Solution {
    public double Power(double base, int exponent) {
        if(exponent == 0) return 1;
        if(exponent == 1) return base;
        if(exponent == -1) return 1/base;
        //递归
        //快速幂 ex：x^6=x^((0*2^0)+(1*2^1)+(1*2^2)
        double half = Power(base, exponent/2);
        double rest = Power(base, exponent%2);
        
        return half*half*rest;
  }
}
```

 
